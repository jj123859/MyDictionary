{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41c2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "from konlpy.tag import Twitter\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tag import untag\n",
    "from nltk import Text\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import FreqDist\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs', {\n",
    "    \"download.default_directory\": \"C:/Users/kimEn/Desktop\", #Change default directory for downloads\n",
    "    \"download.prompt_for_download\": False, #To auto download the file\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "})\n",
    "driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "driver.get('https://paperswithcode.com/sota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bf342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#맨처음 목록 목차 분류작업\n",
    "\n",
    "class_2b_url=[]  #big 분류페이지로\n",
    "class0=[] #class_big와 길이확인**\n",
    "\n",
    "#browse sota대분류 class0 -  중분류 class1  소분류 -pdf설명페이지-pdf다운 길이확인ㅇ\n",
    "#class0=맨처음페이지 대분류 리스트, class0_url=대분류페이지 이동url\n",
    "list1=driver.find_elements(By.CLASS_NAME,'col-md-12 > h4 > a')\n",
    "for i in list1:\n",
    "    class0.append(i.text)\n",
    "    class_2b_url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25f9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#처음목차와 다음 목차 사전 저장& 넘어갈 url수집\n",
    "dic_bAndm={}\n",
    "dic_mAnds={}\n",
    "class_big=[]\n",
    "class1=[]  #class m과 길이비교**\n",
    "class_b2m_url=[]\n",
    "class_small=[]\n",
    "class_m2s_url=[]\n",
    "class_small_dic=[]\n",
    "tmp=[]\n",
    "mid_url=[]\n",
    "\n",
    "#대분류url로 이동\n",
    "for i in range(len(class_2b_url)):\n",
    "    driver.get(class_2b_url[i]) \n",
    "    \n",
    "#class1=computer vision하위 518개 \n",
    "#class1=대분류 내 중분류 리스트, class1_url=see all 클릭시 넘어가는 url / none일경우 소분류로 넘어가기 추가**** \n",
    "    list1=driver.find_elements(By.CLASS_NAME,'infinite-container.featured-task > div.row > div.col-md-12 > h2')\n",
    "    list4=driver.find_elements(By.CLASS_NAME, 'col-lg-12 > h1') #dic1&2(대-중분류) key\n",
    "    list3=driver.find_elements(By.CLASS_NAME,'col-xl-8.card-col.card-col-title > h1') #소분류text\n",
    "    \n",
    "    for i in list4:\n",
    "        class_big.append(i.text)    \n",
    "        for j in list1:             \n",
    "            tmp.append(j.text)\n",
    "            dic_bAndm[i.text]=tmp  #대-중dictionary(list형식)\n",
    "        tmp=[]\n",
    "        \n",
    "#         for k in list3:\n",
    "#             class_small_dic.append(k.text)\n",
    "#             dic_mAnds[class1]=class_small_dic   #중-소분류 사전 수정\n",
    "    \n",
    "    #mid_url = 중분류에서 바로 소분류로 넘어가는 url\n",
    "    mid_url_elem=driver.find_elements(By.CLASS_NAME,'card > a')\n",
    "    for i in mid_url_elem:\n",
    "        if i not in mid_url:\n",
    "            mid_url.append(i.get_attribute('href'))\n",
    "    \n",
    "    list2 = driver.find_elements(By.CLASS_NAME,'sota-all-tasks > a')\n",
    "    for i in list2:          \n",
    "            class_b2m_url.append(i.get_attribute('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d8b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#중분류 모두보기 있는 경우 앞과 겹치지 않게 url 수집 mid_url에 저장\n",
    "\n",
    "for i in range(len(class_b2m_url)):\n",
    "    driver.get(class_b2m_url[i])\n",
    "    list4=driver.find_elements(By.CLASS_NAME,'card-title')\n",
    "    list5=driver.find_elements(By.CLASS_NAME,'card > a')\n",
    "    \n",
    "#      #소분류\n",
    "#     for i in list4:\n",
    "#         if i not in list4:\n",
    "#             class_small.append(i.text)\n",
    "     \n",
    "    #중분류 모두보기에서 소분류 url 수집\n",
    "    for i in list5:\n",
    "        if i not in mid_url:\n",
    "            mid_url.append(i.get_attribute('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e56ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#목록 df저장/csv저장-없는 것만 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2440e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 제목, 상세 url 수집\n",
    "# classname>css section\n",
    "\n",
    "title = []\n",
    "url = []\n",
    "pdf=[]\n",
    "\n",
    "#mid_url(소분류 url) 반복하면서 title, url 리스트 생성\n",
    "for n,i in enumerate(mid_url):\n",
    "    if n<100:\n",
    "        driver.get(f'{i}')\n",
    "        \n",
    "\n",
    "    #title, url\n",
    "        Tlist=driver.find_elements(By.CLASS_NAME,'col-lg-9.item-content > h1 > a')\n",
    "        for i in Tlist:\n",
    "            if i.get_attribute not in url and i.text not in title: \n",
    "                title.append(i.text)\n",
    "                url.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05e8367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_url 수집\n",
    "for i in range(len(url)):\n",
    "    \n",
    "    driver.get(url[i])\n",
    "    pdf_url=driver.find_elements(By.CLASS_NAME,'badge.badge-light')[0].get_attribute('href')\n",
    "    \n",
    "    if pdf_url not in pdf:\n",
    "        pdf.append(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539e5bf9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition',\n",
       " 'https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large',\n",
       " 'https://paperswithcode.com/paper/mobilenets-efficient-convolutional-neural',\n",
       " 'https://paperswithcode.com/paper/densely-connected-convolutional-networks',\n",
       " 'https://paperswithcode.com/paper/cspnet-a-new-backbone-that-can-enhance',\n",
       " 'https://paperswithcode.com/paper/mobilenetv2-inverted-residuals-and-linear',\n",
       " 'https://paperswithcode.com/paper/grad-cam-visual-explanations-from-deep',\n",
       " 'https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for',\n",
       " 'https://paperswithcode.com/paper/rethinking-the-inception-architecture-for',\n",
       " 'https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1',\n",
       " 'https://paperswithcode.com/paper/distilling-the-knowledge-in-a-neural-network',\n",
       " 'https://paperswithcode.com/paper/well-read-students-learn-better-the-impact-of',\n",
       " 'https://paperswithcode.com/paper/distilbert-a-distilled-version-of-bert',\n",
       " 'https://paperswithcode.com/paper/fastspeech-2-fast-and-high-quality-end-to-end',\n",
       " 'https://paperswithcode.com/paper/grad-cam-improved-visual-explanations-for',\n",
       " 'https://paperswithcode.com/paper/making-monolingual-sentence-embeddings',\n",
       " 'https://paperswithcode.com/paper/sequence-level-knowledge-distillation',\n",
       " 'https://paperswithcode.com/paper/paying-more-attention-to-attention-improving',\n",
       " 'https://paperswithcode.com/paper/190910351',\n",
       " 'https://paperswithcode.com/paper/network-pruning-via-transformable',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/matching-networks-for-one-shot-learning',\n",
       " 'https://paperswithcode.com/paper/learning-transferable-visual-models-from',\n",
       " 'https://paperswithcode.com/paper/on-first-order-meta-learning-algorithms',\n",
       " 'https://paperswithcode.com/paper/meta-dataset-a-dataset-of-datasets-for',\n",
       " 'https://paperswithcode.com/paper/learning-to-compare-relation-network-for-few',\n",
       " 'https://paperswithcode.com/paper/how-to-train-your-maml',\n",
       " 'https://paperswithcode.com/paper/meta-learning-with-differentiable-convex',\n",
       " 'https://paperswithcode.com/paper/simpleshot-revisiting-nearest-neighbor',\n",
       " 'https://paperswithcode.com/paper/deep-anomaly-detection-with-outlier-exposure',\n",
       " 'https://paperswithcode.com/paper/likelihood-ratios-for-out-of-distribution',\n",
       " 'https://paperswithcode.com/paper/detecting-out-of-distribution-examples-with',\n",
       " 'https://paperswithcode.com/paper/hierarchical-vaes-know-what-they-don-t-know',\n",
       " 'https://paperswithcode.com/paper/likelihood-regret-an-out-of-distribution',\n",
       " 'https://paperswithcode.com/paper/improved-contrastive-divergence-training-of-1',\n",
       " 'https://paperswithcode.com/paper/a-simple-fix-to-mahalanobis-distance-for',\n",
       " 'https://paperswithcode.com/paper/input-complexity-and-out-of-distribution',\n",
       " 'https://paperswithcode.com/paper/generalized-odin-detecting-out-of',\n",
       " 'https://paperswithcode.com/paper/neural-networks-out-of-distribution-detection',\n",
       " 'https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for',\n",
       " 'https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1',\n",
       " 'https://paperswithcode.com/paper/autoaugment-learning-augmentation-policies',\n",
       " 'https://paperswithcode.com/paper/training-data-efficient-image-transformers',\n",
       " 'https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image',\n",
       " 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1',\n",
       " 'https://paperswithcode.com/paper/transformer-in-transformer',\n",
       " 'https://paperswithcode.com/paper/gpipe-efficient-training-of-giant-neural',\n",
       " 'https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training',\n",
       " 'https://paperswithcode.com/paper/gradient-centralization-a-new-optimization',\n",
       " 'https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical',\n",
       " 'https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/mmdetection-open-mmlab-detection-toolbox-and',\n",
       " 'https://paperswithcode.com/paper/mobilenetv2-inverted-residuals-and-linear',\n",
       " 'https://paperswithcode.com/paper/pointnet-deep-learning-on-point-sets-for-3d',\n",
       " 'https://paperswithcode.com/paper/fcos-fully-convolutional-one-stage-object',\n",
       " 'https://paperswithcode.com/paper/segnet-a-deep-convolutional-encoder-decoder',\n",
       " 'https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable',\n",
       " 'https://paperswithcode.com/paper/rethinking-atrous-convolution-for-semantic',\n",
       " 'https://paperswithcode.com/paper/brain-tumor-segmentation-with-deep-neural',\n",
       " 'https://paperswithcode.com/paper/automatic-brain-tumor-segmentation-using-1',\n",
       " 'https://paperswithcode.com/paper/brain-tumor-segmentation-and-radiomics',\n",
       " 'https://paperswithcode.com/paper/the-kits19-challenge-data-300-kidney-tumor',\n",
       " 'https://paperswithcode.com/paper/3d-mri-brain-tumor-segmentation-using',\n",
       " 'https://paperswithcode.com/paper/the-liver-tumor-segmentation-benchmark-lits',\n",
       " 'https://paperswithcode.com/paper/automatic-liver-and-tumor-segmentation-of-ct',\n",
       " 'https://paperswithcode.com/paper/mri-tumor-segmentation-with-densely-connected',\n",
       " 'https://paperswithcode.com/paper/autofocus-layer-for-semantic-segmentation',\n",
       " 'https://paperswithcode.com/paper/association-of-genomic-subtypes-of-lower',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/resnest-split-attention-networks',\n",
       " 'https://paperswithcode.com/paper/end-to-end-object-detection-with-transformers',\n",
       " 'https://paperswithcode.com/paper/solov2-dynamic-faster-and-stronger',\n",
       " 'https://paperswithcode.com/paper/panoptic-feature-pyramid-networks',\n",
       " 'https://paperswithcode.com/paper/espnet-efficient-spatial-pyramid-of-dilated',\n",
       " 'https://paperswithcode.com/paper/centermask-real-time-anchor-free-instance-1',\n",
       " 'https://paperswithcode.com/paper/hierarchical-multi-scale-attention-for',\n",
       " 'https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision',\n",
       " 'https://paperswithcode.com/paper/panoptic-deeplab-a-simple-strong-and-fast',\n",
       " 'https://paperswithcode.com/paper/pointnet-deep-learning-on-point-sets-for-3d',\n",
       " 'https://paperswithcode.com/paper/pointnet-deep-hierarchical-feature-learning',\n",
       " 'https://paperswithcode.com/paper/squeezeseg-convolutional-neural-nets-with',\n",
       " 'https://paperswithcode.com/paper/kpconv-flexible-and-deformable-convolution',\n",
       " 'https://paperswithcode.com/paper/3d-semantic-segmentation-with-submanifold',\n",
       " 'https://paperswithcode.com/paper/partnet-a-large-scale-benchmark-for-fine',\n",
       " 'https://paperswithcode.com/paper/4d-spatio-temporal-convnets-minkowski',\n",
       " 'https://paperswithcode.com/paper/191111236',\n",
       " 'https://paperswithcode.com/paper/salsanext-fast-semantic-segmentation-of-lidar',\n",
       " 'https://paperswithcode.com/paper/shape-aware-semi-supervised-3d-semantic',\n",
       " 'https://paperswithcode.com/paper/constrained-cnn-losses-for-weakly-supervised',\n",
       " 'https://paperswithcode.com/paper/weakly-supervised-learning-of-instance',\n",
       " 'https://paperswithcode.com/paper/weakly-and-semi-supervised-learning-of-a-dcnn',\n",
       " 'https://paperswithcode.com/paper/puzzle-cam-improved-localization-via-matching',\n",
       " 'https://paperswithcode.com/paper/fully-convolutional-multi-class-multiple',\n",
       " 'https://paperswithcode.com/paper/learning-pixel-level-semantic-affinity-with',\n",
       " 'https://paperswithcode.com/paper/integral-object-mining-via-online-attention',\n",
       " 'https://paperswithcode.com/paper/histosegnet-semantic-segmentation-of',\n",
       " 'https://paperswithcode.com/paper/self-supervised-equivariant-attention',\n",
       " 'https://paperswithcode.com/paper/mining-cross-image-semantics-for-weakly',\n",
       " 'https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition',\n",
       " 'https://paperswithcode.com/paper/yolov3-an-incremental-improvement',\n",
       " 'https://paperswithcode.com/paper/yolo9000-better-faster-stronger',\n",
       " 'https://paperswithcode.com/paper/yolov4-optimal-speed-and-accuracy-of-object',\n",
       " 'https://paperswithcode.com/paper/focal-loss-for-dense-object-detection',\n",
       " 'https://paperswithcode.com/paper/ssd-single-shot-multibox-detector',\n",
       " 'https://paperswithcode.com/paper/faster-r-cnn-towards-real-time-object',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/mmdetection-open-mmlab-detection-toolbox-and',\n",
       " 'https://paperswithcode.com/paper/you-only-look-once-unified-real-time-object',\n",
       " 'https://paperswithcode.com/paper/frustum-pointnets-for-3d-object-detection',\n",
       " 'https://paperswithcode.com/paper/voxelnet-end-to-end-learning-for-point-cloud',\n",
       " 'https://paperswithcode.com/paper/nuscenes-a-multimodal-dataset-for-autonomous',\n",
       " 'https://paperswithcode.com/paper/deep-hough-voting-for-3d-object-detection-in',\n",
       " 'https://paperswithcode.com/paper/complex-yolo-real-time-3d-object-detection-on',\n",
       " 'https://paperswithcode.com/paper/pointrcnn-3d-object-proposal-generation-and',\n",
       " 'https://paperswithcode.com/paper/3d-bounding-box-estimation-using-deep',\n",
       " 'https://paperswithcode.com/paper/center-based-3d-object-detection-and-tracking',\n",
       " 'https://paperswithcode.com/paper/pointpillars-fast-encoders-for-object',\n",
       " 'https://paperswithcode.com/paper/cubeslam-monocular-3d-object-detection-and',\n",
       " 'https://paperswithcode.com/paper/u-2-net-going-deeper-with-nested-u-structure',\n",
       " 'https://paperswithcode.com/paper/res2net-a-new-multi-scale-backbone',\n",
       " 'https://paperswithcode.com/paper/rgb-d-salient-object-detection-a-survey',\n",
       " 'https://paperswithcode.com/paper/a-simple-pooling-based-design-for-real-time',\n",
       " 'https://paperswithcode.com/paper/f3net-fusion-feedback-and-focus-for-salient',\n",
       " 'https://paperswithcode.com/paper/uncertainty-inspired-rgb-d-saliency-detection',\n",
       " 'https://paperswithcode.com/paper/reverse-attention-for-salient-object',\n",
       " 'https://paperswithcode.com/paper/basnet-boundary-aware-salient-object',\n",
       " 'https://paperswithcode.com/paper/egnet-edge-guidance-network-for-salient',\n",
       " 'https://paperswithcode.com/paper/cagnet-content-aware-guidance-for-salient',\n",
       " 'https://paperswithcode.com/paper/yolov3-an-incremental-improvement',\n",
       " 'https://paperswithcode.com/paper/yolo9000-better-faster-stronger',\n",
       " 'https://paperswithcode.com/paper/yolov4-optimal-speed-and-accuracy-of-object',\n",
       " 'https://paperswithcode.com/paper/focal-loss-for-dense-object-detection',\n",
       " 'https://paperswithcode.com/paper/faster-r-cnn-towards-real-time-object',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/you-only-look-once-unified-real-time-object',\n",
       " 'https://paperswithcode.com/paper/cspnet-a-new-backbone-that-can-enhance',\n",
       " 'https://paperswithcode.com/paper/objects-as-points',\n",
       " 'https://paperswithcode.com/paper/efficientdet-scalable-and-efficient-object',\n",
       " 'https://paperswithcode.com/paper/rgb-d-salient-object-detection-a-survey',\n",
       " 'https://paperswithcode.com/paper/uncertainty-inspired-rgb-d-saliency-detection',\n",
       " 'https://paperswithcode.com/paper/pdnet-prior-model-guided-depth-enhanced',\n",
       " 'https://paperswithcode.com/paper/contrast-prior-and-fluid-pyramid-integration',\n",
       " 'https://paperswithcode.com/paper/rethinking-rgb-d-salient-object-detection',\n",
       " 'https://paperswithcode.com/paper/bbs-net-rgb-d-salient-object-detection-with-a',\n",
       " 'https://paperswithcode.com/paper/cross-modal-weighting-network-for-rgb-d',\n",
       " 'https://paperswithcode.com/paper/accurate-rgb-d-salient-object-detection-via',\n",
       " 'https://paperswithcode.com/paper/siamese-network-for-rgb-d-salient-object',\n",
       " 'https://paperswithcode.com/paper/progressively-complementarity-aware-fusion',\n",
       " 'https://paperswithcode.com/paper/domain-adversarial-training-of-neural',\n",
       " 'https://paperswithcode.com/paper/generalized-end-to-end-loss-for-speaker',\n",
       " 'https://paperswithcode.com/paper/language-models-are-few-shot-learners',\n",
       " 'https://paperswithcode.com/paper/superpoint-self-supervised-interest-point',\n",
       " 'https://paperswithcode.com/paper/unsupervised-domain-adaptation-by',\n",
       " 'https://paperswithcode.com/paper/adversarial-discriminative-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/two-at-once-enhancing-learning-and',\n",
       " 'https://paperswithcode.com/paper/learning-to-adapt-structured-output-space-for',\n",
       " 'https://paperswithcode.com/paper/unsupervised-image-to-image-translation',\n",
       " 'https://paperswithcode.com/paper/decaf-a-deep-convolutional-activation-feature',\n",
       " 'https://paperswithcode.com/paper/unsupervised-domain-adaptation-by',\n",
       " 'https://paperswithcode.com/paper/adversarial-discriminative-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/person-transfer-gan-to-bridge-domain-gap-for',\n",
       " 'https://paperswithcode.com/paper/deep-coral-correlation-alignment-for-deep',\n",
       " 'https://paperswithcode.com/paper/unsupervised-pixel-level-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/maximum-classifier-discrepancy-for',\n",
       " 'https://paperswithcode.com/paper/rescaling-egocentric-vision',\n",
       " 'https://paperswithcode.com/paper/domain-separation-networks',\n",
       " 'https://paperswithcode.com/paper/domain-adaptive-faster-r-cnn-for-object',\n",
       " 'https://paperswithcode.com/paper/adamatch-a-unified-approach-to-semi',\n",
       " 'https://paperswithcode.com/paper/mixup-beyond-empirical-risk-minimization',\n",
       " 'https://paperswithcode.com/paper/cutmix-regularization-strategy-to-train',\n",
       " 'https://paperswithcode.com/paper/domain-adversarial-training-of-neural',\n",
       " 'https://paperswithcode.com/paper/improved-regularization-of-convolutional',\n",
       " 'https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision',\n",
       " 'https://paperswithcode.com/paper/a-convnet-for-the-2020s',\n",
       " 'https://paperswithcode.com/paper/invariant-risk-minimization',\n",
       " 'https://paperswithcode.com/paper/augmix-a-simple-data-processing-method-to',\n",
       " 'https://paperswithcode.com/paper/benchmarking-neural-network-robustness-to-2',\n",
       " 'https://paperswithcode.com/paper/on-the-limits-of-cross-domain-generalization',\n",
       " 'https://paperswithcode.com/paper/importance-weighted-adversarial-nets-for',\n",
       " 'https://paperswithcode.com/paper/partial-adversarial-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/unsupervised-domain-adaptation-an-adaptive',\n",
       " 'https://paperswithcode.com/paper/less-confusion-more-transferable-minimum',\n",
       " 'https://paperswithcode.com/paper/007-democratically-finding-the-cause-of',\n",
       " 'https://paperswithcode.com/paper/learning-to-transfer-examples-for-partial',\n",
       " 'https://paperswithcode.com/paper/universal-domain-adaptation-through-self',\n",
       " 'https://paperswithcode.com/paper/do-we-really-need-to-access-the-source-data',\n",
       " 'https://paperswithcode.com/paper/a-balanced-and-uncertainty-aware-approach-for',\n",
       " 'https://paperswithcode.com/paper/deep-residual-correction-network-for-partial',\n",
       " 'https://paperswithcode.com/paper/ovanet-one-vs-all-network-for-universal',\n",
       " 'https://paperswithcode.com/paper/universal-domain-adaptation-through-self',\n",
       " 'https://paperswithcode.com/paper/buda-boundless-unsupervised-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/on-universal-black-box-domain-adaptation',\n",
       " 'https://paperswithcode.com/paper/domain-consensus-clustering-for-universal',\n",
       " 'https://paperswithcode.com/paper/distance-based-hyperspherical-classification',\n",
       " 'https://paperswithcode.com/paper/visda-2021-competition-universal-domain',\n",
       " 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of',\n",
       " 'https://paperswithcode.com/paper/wasserstein-gan',\n",
       " 'https://paperswithcode.com/paper/improved-training-of-wasserstein-gans',\n",
       " 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved',\n",
       " 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for',\n",
       " 'https://paperswithcode.com/paper/gans-trained-by-a-two-time-scale-update-rule',\n",
       " 'https://paperswithcode.com/paper/self-attention-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/improved-techniques-for-training-gans',\n",
       " 'https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a',\n",
       " 'https://paperswithcode.com/paper/generative-adversarial-text-to-image',\n",
       " 'https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition',\n",
       " 'https://paperswithcode.com/paper/unpaired-image-to-image-translation-using',\n",
       " 'https://paperswithcode.com/paper/image-to-image-translation-with-conditional',\n",
       " 'https://paperswithcode.com/paper/stargan-unified-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/u-gat-it-unsupervised-generative-attentional',\n",
       " 'https://paperswithcode.com/paper/semantic-image-synthesis-with-spatially',\n",
       " 'https://paperswithcode.com/paper/high-resolution-image-synthesis-and-semantic',\n",
       " 'https://paperswithcode.com/paper/multimodal-unsupervised-image-to-image',\n",
       " 'https://paperswithcode.com/paper/everybody-dance-now',\n",
       " 'https://paperswithcode.com/paper/stargan-v2-diverse-image-synthesis-for',\n",
       " 'https://paperswithcode.com/paper/image-inpainting-for-irregular-holes-using',\n",
       " 'https://paperswithcode.com/paper/free-form-image-inpainting-with-gated',\n",
       " 'https://paperswithcode.com/paper/generative-image-inpainting-with-contextual',\n",
       " 'https://paperswithcode.com/paper/edgeconnect-generative-image-inpainting-with',\n",
       " 'https://paperswithcode.com/paper/implicit-neural-representations-with-periodic',\n",
       " 'https://paperswithcode.com/paper/deep-image-prior',\n",
       " 'https://paperswithcode.com/paper/generative-modeling-by-estimating-gradients',\n",
       " 'https://paperswithcode.com/paper/semantic-image-inpainting-with-deep',\n",
       " 'https://paperswithcode.com/paper/score-based-generative-modeling-through-1',\n",
       " 'https://paperswithcode.com/paper/contextual-residual-aggregation-for-ultra',\n",
       " 'https://paperswithcode.com/paper/unsupervised-representation-learning-with-1',\n",
       " 'https://paperswithcode.com/paper/improved-training-of-wasserstein-gans',\n",
       " 'https://paperswithcode.com/paper/self-attention-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/improved-techniques-for-training-gans',\n",
       " 'https://paperswithcode.com/paper/conditional-image-synthesis-with-auxiliary',\n",
       " 'https://paperswithcode.com/paper/large-scale-gan-training-for-high-fidelity',\n",
       " 'https://paperswithcode.com/paper/training-generative-adversarial-networks-with-2',\n",
       " 'https://paperswithcode.com/paper/high-resolution-image-synthesis-and-semantic',\n",
       " 'https://paperswithcode.com/paper/conditional-image-generation-with-pixelcnn',\n",
       " 'https://paperswithcode.com/paper/cgans-with-projection-discriminator',\n",
       " 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved',\n",
       " 'https://paperswithcode.com/paper/everybody-dance-now',\n",
       " 'https://paperswithcode.com/paper/faceshifter-towards-high-fidelity-and',\n",
       " 'https://paperswithcode.com/paper/learning-a-model-of-facial-shape-and',\n",
       " 'https://paperswithcode.com/paper/ganimation-anatomically-aware-facial',\n",
       " 'https://paperswithcode.com/paper/encoding-in-style-a-stylegan-encoder-for',\n",
       " 'https://paperswithcode.com/paper/interpreting-the-latent-space-of-gans-for',\n",
       " 'https://paperswithcode.com/paper/few-shot-knowledge-transfer-for-fine-grained',\n",
       " 'https://paperswithcode.com/paper/wav2pix-speech-conditioned-face-generation',\n",
       " 'https://paperswithcode.com/paper/anigan-style-guided-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/yolov4-optimal-speed-and-accuracy-of-object',\n",
       " 'https://paperswithcode.com/paper/specaugment-a-simple-data-augmentation-method',\n",
       " 'https://paperswithcode.com/paper/improved-regularization-of-convolutional',\n",
       " 'https://paperswithcode.com/paper/improved-baselines-with-momentum-contrastive',\n",
       " 'https://paperswithcode.com/paper/autoaugment-learning-augmentation-policies',\n",
       " 'https://paperswithcode.com/paper/denser-deep-evolutionary-network-structured',\n",
       " 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1',\n",
       " 'https://paperswithcode.com/paper/3d-u-net-learning-dense-volumetric',\n",
       " 'https://paperswithcode.com/paper/random-erasing-data-augmentation',\n",
       " 'https://paperswithcode.com/paper/supervised-contrastive-learning',\n",
       " 'https://paperswithcode.com/paper/improved-regularization-of-convolutional',\n",
       " 'https://paperswithcode.com/paper/autoaugment-learning-augmentation-policies',\n",
       " 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1',\n",
       " 'https://paperswithcode.com/paper/random-erasing-data-augmentation',\n",
       " 'https://paperswithcode.com/paper/fast-autoaugment',\n",
       " 'https://paperswithcode.com/paper/augmentor-an-image-augmentation-library-for',\n",
       " 'https://paperswithcode.com/paper/learning-data-augmentation-strategies-for',\n",
       " 'https://paperswithcode.com/paper/albumentations-fast-and-flexible-image',\n",
       " 'https://paperswithcode.com/paper/kornia-an-open-source-differentiable-computer',\n",
       " 'https://paperswithcode.com/paper/190505393',\n",
       " 'https://paperswithcode.com/paper/eda-easy-data-augmentation-techniques-for',\n",
       " 'https://paperswithcode.com/paper/contextual-augmentation-data-augmentation-by',\n",
       " 'https://paperswithcode.com/paper/data-augmentation-via-dependency-tree-1',\n",
       " 'https://paperswithcode.com/paper/learning-to-compose-domain-specific',\n",
       " 'https://paperswithcode.com/paper/sequence-to-sequence-data-augmentation-for',\n",
       " 'https://paperswithcode.com/paper/text-data-augmentation-made-simple-by',\n",
       " 'https://paperswithcode.com/paper/improving-short-text-classification-through',\n",
       " 'https://paperswithcode.com/paper/text-augmentation-for-language-models-in-high',\n",
       " 'https://paperswithcode.com/paper/better-robustness-by-more-coverage',\n",
       " 'https://paperswithcode.com/paper/gpt3mix-leveraging-large-scale-language',\n",
       " 'https://paperswithcode.com/paper/subtab-subsetting-features-of-tabular-data',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/on-first-order-meta-learning-algorithms',\n",
       " 'https://paperswithcode.com/paper/meta-dataset-a-dataset-of-datasets-for',\n",
       " 'https://paperswithcode.com/paper/learning-to-compare-relation-network-for-few',\n",
       " 'https://paperswithcode.com/paper/learning-to-reweight-examples-for-robust-deep',\n",
       " 'https://paperswithcode.com/paper/meta-learning-for-semi-supervised-few-shot',\n",
       " 'https://paperswithcode.com/paper/how-to-train-your-maml',\n",
       " 'https://paperswithcode.com/paper/learning-to-reinforcement-learn',\n",
       " 'https://paperswithcode.com/paper/meta-sgd-learning-to-learn-quickly-for-few',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/language-models-are-few-shot-learners',\n",
       " 'https://paperswithcode.com/paper/matching-networks-for-one-shot-learning',\n",
       " 'https://paperswithcode.com/paper/on-first-order-meta-learning-algorithms',\n",
       " 'https://paperswithcode.com/paper/learning-to-compare-relation-network-for-few',\n",
       " 'https://paperswithcode.com/paper/how-to-train-your-maml',\n",
       " 'https://paperswithcode.com/paper/meta-sgd-learning-to-learn-quickly-for-few',\n",
       " 'https://paperswithcode.com/paper/meta-learning-with-differentiable-convex',\n",
       " 'https://paperswithcode.com/paper/compact-bilinear-pooling',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/realtime-multi-person-2d-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/convolutional-pose-machines',\n",
       " 'https://paperswithcode.com/paper/openpose-realtime-multi-person-2d-pose',\n",
       " 'https://paperswithcode.com/paper/stacked-hourglass-networks-for-human-pose',\n",
       " 'https://paperswithcode.com/paper/high-resolution-representations-for-labeling',\n",
       " 'https://paperswithcode.com/paper/deep-high-resolution-representation-learning',\n",
       " 'https://paperswithcode.com/paper/190807919',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/densepose-dense-human-pose-estimation-in-the',\n",
       " 'https://paperswithcode.com/paper/image-inpainting-for-irregular-holes-using',\n",
       " 'https://paperswithcode.com/paper/free-form-image-inpainting-with-gated',\n",
       " 'https://paperswithcode.com/paper/generative-image-inpainting-with-contextual',\n",
       " 'https://paperswithcode.com/paper/edgeconnect-generative-image-inpainting-with',\n",
       " 'https://paperswithcode.com/paper/implicit-neural-representations-with-periodic',\n",
       " 'https://paperswithcode.com/paper/deep-image-prior',\n",
       " 'https://paperswithcode.com/paper/generative-modeling-by-estimating-gradients',\n",
       " 'https://paperswithcode.com/paper/semantic-image-inpainting-with-deep',\n",
       " 'https://paperswithcode.com/paper/score-based-generative-modeling-through-1',\n",
       " 'https://paperswithcode.com/paper/contextual-residual-aggregation-for-ultra',\n",
       " 'https://paperswithcode.com/paper/learning-to-see-in-the-dark',\n",
       " 'https://paperswithcode.com/paper/deblurgan-blind-motion-deblurring-using',\n",
       " 'https://paperswithcode.com/paper/edvr-video-restoration-with-enhanced',\n",
       " 'https://paperswithcode.com/paper/defmo-deblurring-and-shape-recovery-of-fast',\n",
       " 'https://paperswithcode.com/paper/scale-recurrent-network-for-deep-image',\n",
       " 'https://paperswithcode.com/paper/deblurgan-v2-deblurring-orders-of-magnitude',\n",
       " 'https://paperswithcode.com/paper/plug-and-play-image-restoration-with-deep',\n",
       " 'https://paperswithcode.com/paper/multi-stage-progressive-image-restoration',\n",
       " 'https://paperswithcode.com/paper/uformer-a-general-u-shaped-transformer-for',\n",
       " 'https://paperswithcode.com/paper/restormer-efficient-transformer-for-high',\n",
       " 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved',\n",
       " 'https://paperswithcode.com/paper/everybody-dance-now',\n",
       " 'https://paperswithcode.com/paper/faceshifter-towards-high-fidelity-and',\n",
       " 'https://paperswithcode.com/paper/learning-a-model-of-facial-shape-and',\n",
       " 'https://paperswithcode.com/paper/ganimation-anatomically-aware-facial',\n",
       " 'https://paperswithcode.com/paper/encoding-in-style-a-stylegan-encoder-for',\n",
       " 'https://paperswithcode.com/paper/interpreting-the-latent-space-of-gans-for',\n",
       " 'https://paperswithcode.com/paper/few-shot-knowledge-transfer-for-fine-grained',\n",
       " 'https://paperswithcode.com/paper/wav2pix-speech-conditioned-face-generation',\n",
       " 'https://paperswithcode.com/paper/anigan-style-guided-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/deepfacelab-a-simple-flexible-and-extensible',\n",
       " 'https://paperswithcode.com/paper/faceforensics-learning-to-detect-manipulated',\n",
       " 'https://paperswithcode.com/paper/faceshifter-towards-high-fidelity-and',\n",
       " 'https://paperswithcode.com/paper/the-deepfake-detection-challenge-dataset',\n",
       " 'https://paperswithcode.com/paper/mesonet-a-compact-facial-video-forgery',\n",
       " 'https://paperswithcode.com/paper/celeb-df-a-new-dataset-for-deepfake-forensics',\n",
       " 'https://paperswithcode.com/paper/in-ictu-oculi-exposing-ai-generated-fake-face',\n",
       " 'https://paperswithcode.com/paper/exposing-deepfake-videos-by-detecting-face',\n",
       " 'https://paperswithcode.com/paper/face-x-ray-for-more-general-face-forgery',\n",
       " 'https://paperswithcode.com/paper/fdftnet-facing-off-fake-images-using-fake',\n",
       " 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of',\n",
       " 'https://paperswithcode.com/paper/wasserstein-gan',\n",
       " 'https://paperswithcode.com/paper/improved-training-of-wasserstein-gans',\n",
       " 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved',\n",
       " 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for',\n",
       " 'https://paperswithcode.com/paper/gans-trained-by-a-two-time-scale-update-rule',\n",
       " 'https://paperswithcode.com/paper/self-attention-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/improved-techniques-for-training-gans',\n",
       " 'https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a',\n",
       " 'https://paperswithcode.com/paper/generative-adversarial-text-to-image',\n",
       " 'https://paperswithcode.com/paper/photo-realistic-single-image-super-resolution',\n",
       " 'https://paperswithcode.com/paper/perceptual-losses-for-real-time-style',\n",
       " 'https://paperswithcode.com/paper/image-super-resolution-using-deep',\n",
       " 'https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a',\n",
       " 'https://paperswithcode.com/paper/enhanced-deep-residual-networks-for-single',\n",
       " 'https://paperswithcode.com/paper/real-time-single-image-and-video-super',\n",
       " 'https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative',\n",
       " 'https://paperswithcode.com/paper/deep-back-projection-networks-for-super',\n",
       " 'https://paperswithcode.com/paper/pulse-self-supervised-photo-upsampling-via',\n",
       " 'https://paperswithcode.com/paper/beyond-a-gaussian-denoiser-residual-learning',\n",
       " 'https://paperswithcode.com/paper/learning-a-model-of-facial-shape-and',\n",
       " 'https://paperswithcode.com/paper/3d-faces-in-motion-fully-automatic',\n",
       " 'https://paperswithcode.com/paper/capture-learning-and-synthesis-of-3d-speaking',\n",
       " 'https://paperswithcode.com/paper/audio-driven-talking-face-video-generation',\n",
       " 'https://paperswithcode.com/paper/learning-an-animatable-detailed-3d-face-model',\n",
       " 'https://paperswithcode.com/paper/facial-synthesizing-dynamic-talking-face-with',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/realtime-multi-person-2d-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/convolutional-pose-machines',\n",
       " 'https://paperswithcode.com/paper/openpose-realtime-multi-person-2d-pose',\n",
       " 'https://paperswithcode.com/paper/stacked-hourglass-networks-for-human-pose',\n",
       " 'https://paperswithcode.com/paper/high-resolution-representations-for-labeling',\n",
       " 'https://paperswithcode.com/paper/deep-high-resolution-representation-learning',\n",
       " 'https://paperswithcode.com/paper/190807919',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/densepose-dense-human-pose-estimation-in-the',\n",
       " 'https://paperswithcode.com/paper/convolutional-pose-machines',\n",
       " 'https://paperswithcode.com/paper/spatial-temporal-graph-convolutional-networks-1',\n",
       " 'https://paperswithcode.com/paper/a-simple-yet-effective-baseline-for-3d-human',\n",
       " 'https://paperswithcode.com/paper/lifting-from-the-deep-convolutional-3d-pose',\n",
       " 'https://paperswithcode.com/paper/3d-human-pose-estimation-in-video-with',\n",
       " 'https://paperswithcode.com/paper/v2v-posenet-voxel-to-voxel-prediction-network',\n",
       " 'https://paperswithcode.com/paper/multi-garment-net-learning-to-dress-3d-people',\n",
       " 'https://paperswithcode.com/paper/towards-3d-human-pose-estimation-in-the-wild',\n",
       " 'https://paperswithcode.com/paper/end-to-end-recovery-of-human-shape-and-pose',\n",
       " 'https://paperswithcode.com/paper/xnect-real-time-multi-person-3d-human-pose',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/objects-as-points',\n",
       " 'https://paperswithcode.com/paper/realtime-multi-person-2d-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/openpose-realtime-multi-person-2d-pose',\n",
       " 'https://paperswithcode.com/paper/hand-keypoint-detection-in-single-images',\n",
       " 'https://paperswithcode.com/paper/deep-high-resolution-representation-learning',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/simple-baselines-for-human-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/deepercut-a-deeper-stronger-and-faster-multi',\n",
       " 'https://paperswithcode.com/paper/arttrack-articulated-multi-person-tracking-in',\n",
       " 'https://paperswithcode.com/paper/a-simple-yet-effective-baseline-for-3d-human',\n",
       " 'https://paperswithcode.com/paper/lifting-from-the-deep-convolutional-3d-pose',\n",
       " 'https://paperswithcode.com/paper/single-shot-multi-person-3d-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/vibe-video-inference-for-human-body-pose-and',\n",
       " 'https://paperswithcode.com/paper/unsupervised-learning-of-shape-and-pose-with',\n",
       " 'https://paperswithcode.com/paper/integral-human-pose-regression',\n",
       " 'https://paperswithcode.com/paper/depth-based-3d-hand-pose-estimation-from',\n",
       " 'https://paperswithcode.com/paper/2d3d-pose-estimation-and-action-recognition',\n",
       " 'https://paperswithcode.com/paper/a-generalizable-approach-for-multi-view-3d',\n",
       " 'https://paperswithcode.com/paper/3d-pose-estimation-for-fine-grained-object',\n",
       " 'https://paperswithcode.com/paper/mask-r-cnn',\n",
       " 'https://paperswithcode.com/paper/realtime-multi-person-2d-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/deep-high-resolution-representation-learning',\n",
       " 'https://paperswithcode.com/paper/bottom-up-higher-resolution-networks-for',\n",
       " 'https://paperswithcode.com/paper/deepercut-a-deeper-stronger-and-faster-multi',\n",
       " 'https://paperswithcode.com/paper/real-time-2d-multi-person-pose-estimation-on',\n",
       " 'https://paperswithcode.com/paper/arttrack-articulated-multi-person-tracking-in',\n",
       " 'https://paperswithcode.com/paper/rmpe-regional-multi-person-pose-estimation',\n",
       " 'https://paperswithcode.com/paper/directpose-direct-end-to-end-multi-person',\n",
       " 'https://paperswithcode.com/paper/distribution-aware-coordinate-representation',\n",
       " 'https://paperswithcode.com/paper/yolox-exceeding-yolo-series-in-2021',\n",
       " 'https://paperswithcode.com/paper/multinet-real-time-joint-semantic-reasoning',\n",
       " 'https://paperswithcode.com/paper/squeezedet-unified-small-low-power-fully',\n",
       " 'https://paperswithcode.com/paper/nuscenes-a-multimodal-dataset-for-autonomous',\n",
       " 'https://paperswithcode.com/paper/key-points-estimation-and-point-instance',\n",
       " 'https://paperswithcode.com/paper/complex-yolo-real-time-3d-object-detection-on',\n",
       " 'https://paperswithcode.com/paper/explaining-how-a-deep-neural-network-trained',\n",
       " 'https://paperswithcode.com/paper/scalability-in-perception-for-autonomous',\n",
       " 'https://paperswithcode.com/paper/virtual-to-real-reinforcement-learning-for',\n",
       " 'https://paperswithcode.com/paper/learning-to-drive-in-a-day',\n",
       " 'https://paperswithcode.com/paper/airsim-high-fidelity-visual-and-physical',\n",
       " 'https://paperswithcode.com/paper/flow-architecture-and-benchmarking-for',\n",
       " 'https://paperswithcode.com/paper/nuscenes-a-multimodal-dataset-for-autonomous',\n",
       " 'https://paperswithcode.com/paper/counterfactual-multi-agent-policy-gradients',\n",
       " 'https://paperswithcode.com/paper/dynaslam-tracking-mapping-and-inpainting-in',\n",
       " 'https://paperswithcode.com/paper/lidar-camera-calibration-using-3d-3d-point',\n",
       " 'https://paperswithcode.com/paper/leaf-a-benchmark-for-federated-settings',\n",
       " 'https://paperswithcode.com/paper/deep-dual-resolution-networks-for-real-time',\n",
       " 'https://paperswithcode.com/paper/joint-3d-proposal-generation-and-object',\n",
       " 'https://paperswithcode.com/paper/on-the-importance-of-stereo-for-accurate',\n",
       " 'https://paperswithcode.com/paper/end-to-end-learning-for-self-driving-cars',\n",
       " 'https://paperswithcode.com/paper/explaining-how-a-deep-neural-network-trained',\n",
       " 'https://paperswithcode.com/paper/social-gan-socially-acceptable-trajectories',\n",
       " 'https://paperswithcode.com/paper/openpifpaf-composite-fields-for-semantic',\n",
       " 'https://paperswithcode.com/paper/fast-algorithms-for-convolutional-neural',\n",
       " 'https://paperswithcode.com/paper/learning-a-driving-simulator',\n",
       " 'https://paperswithcode.com/paper/vectornet-encoding-hd-maps-and-agent-dynamics',\n",
       " 'https://paperswithcode.com/paper/visualbackprop-efficient-visualization-of',\n",
       " 'https://paperswithcode.com/paper/pointpainting-sequential-fusion-for-3d-object',\n",
       " 'https://paperswithcode.com/paper/deepxplore-automated-whitebox-testing-of-deep',\n",
       " 'https://paperswithcode.com/paper/visual-inertial-monocular-slam-with-map-reuse',\n",
       " 'https://paperswithcode.com/paper/kimera-an-open-source-library-for-real-time',\n",
       " 'https://paperswithcode.com/paper/sparse-to-dense-depth-prediction-from-sparse',\n",
       " 'https://paperswithcode.com/paper/orb-slam2-an-open-source-slam-system-for',\n",
       " 'https://paperswithcode.com/paper/online-spatial-concept-and-lexical',\n",
       " 'https://paperswithcode.com/paper/incremental-visual-inertial-3d-mesh',\n",
       " 'https://paperswithcode.com/paper/lidartag-a-real-time-fiducial-tag-using-point',\n",
       " 'https://paperswithcode.com/paper/3d-dynamic-scene-graphs-actionable-spatial',\n",
       " 'https://paperswithcode.com/paper/dxslam-a-robust-and-efficient-visual-slam',\n",
       " 'https://paperswithcode.com/paper/semantic-histogram-based-graph-matching-for',\n",
       " 'https://paperswithcode.com/paper/voxelnet-end-to-end-learning-for-point-cloud',\n",
       " 'https://paperswithcode.com/paper/deeptraffic-crowdsourced-hyperparameter',\n",
       " 'https://paperswithcode.com/paper/decentralized-distributed-ppo-solving',\n",
       " 'https://paperswithcode.com/paper/towards-real-time-unsupervised-monocular',\n",
       " 'https://paperswithcode.com/paper/social-nce-contrastive-learning-of-socially',\n",
       " 'https://paperswithcode.com/paper/learning-to-navigate-in-cities-without-a-map',\n",
       " 'https://paperswithcode.com/paper/a-64mw-dnn-based-visual-navigation-engine-for',\n",
       " 'https://paperswithcode.com/paper/a-water-obstacle-separation-and-refinement',\n",
       " 'https://paperswithcode.com/paper/socially-aware-motion-planning-with-deep',\n",
       " 'https://paperswithcode.com/paper/intention-net-integrating-planning-and-deep',\n",
       " 'https://paperswithcode.com/paper/photo-realistic-single-image-super-resolution',\n",
       " 'https://paperswithcode.com/paper/perceptual-losses-for-real-time-style',\n",
       " 'https://paperswithcode.com/paper/image-super-resolution-using-deep',\n",
       " 'https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a',\n",
       " 'https://paperswithcode.com/paper/enhanced-deep-residual-networks-for-single',\n",
       " 'https://paperswithcode.com/paper/real-time-single-image-and-video-super',\n",
       " 'https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative',\n",
       " 'https://paperswithcode.com/paper/deep-back-projection-networks-for-super',\n",
       " 'https://paperswithcode.com/paper/pulse-self-supervised-photo-upsampling-via',\n",
       " 'https://paperswithcode.com/paper/image-restoration-using-convolutional-auto',\n",
       " 'https://paperswithcode.com/paper/photo-realistic-single-image-super-resolution',\n",
       " 'https://paperswithcode.com/paper/perceptual-losses-for-real-time-style',\n",
       " 'https://paperswithcode.com/paper/image-super-resolution-using-deep',\n",
       " 'https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a',\n",
       " 'https://paperswithcode.com/paper/enhanced-deep-residual-networks-for-single',\n",
       " 'https://paperswithcode.com/paper/real-time-single-image-and-video-super',\n",
       " 'https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative',\n",
       " 'https://paperswithcode.com/paper/deep-back-projection-networks-for-super',\n",
       " 'https://paperswithcode.com/paper/pulse-self-supervised-photo-upsampling-via',\n",
       " 'https://paperswithcode.com/paper/beyond-a-gaussian-denoiser-residual-learning',\n",
       " 'https://paperswithcode.com/paper/image-super-resolution-using-deep',\n",
       " 'https://paperswithcode.com/paper/real-time-single-image-and-video-super',\n",
       " 'https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative',\n",
       " 'https://paperswithcode.com/paper/deep-back-projection-networks-for-super',\n",
       " 'https://paperswithcode.com/paper/temporally-coherent-gans-for-video-super',\n",
       " 'https://paperswithcode.com/paper/edvr-video-restoration-with-enhanced',\n",
       " 'https://paperswithcode.com/paper/real-esrgan-training-real-world-blind-super',\n",
       " 'https://paperswithcode.com/paper/video-enhancement-with-task-oriented-flow',\n",
       " 'https://paperswithcode.com/paper/defmo-deblurring-and-shape-recovery-of-fast',\n",
       " 'https://paperswithcode.com/paper/basicvsr-the-search-for-essential-components',\n",
       " 'https://paperswithcode.com/paper/wide-activation-for-efficient-and-accurate',\n",
       " 'https://paperswithcode.com/paper/190503277',\n",
       " 'https://paperswithcode.com/paper/deep-burst-super-resolution',\n",
       " 'https://paperswithcode.com/paper/multi-image-super-resolution-of-remotely',\n",
       " 'https://paperswithcode.com/paper/deep-reparametrization-of-multi-frame-super',\n",
       " 'https://paperswithcode.com/paper/007-democratically-finding-the-cause-of',\n",
       " 'https://paperswithcode.com/paper/deepsum-deep-neural-network-for-super',\n",
       " 'https://paperswithcode.com/paper/highres-net-multi-frame-super-resolution-by',\n",
       " 'https://paperswithcode.com/paper/highres-net-recursive-fusion-for-multi-frame',\n",
       " 'https://paperswithcode.com/paper/permutation-invariance-and-uncertainty-in',\n",
       " 'https://paperswithcode.com/paper/image-super-resolution-by-neural-texture',\n",
       " 'https://paperswithcode.com/paper/dual-camera-super-resolution-with-aligned',\n",
       " 'https://paperswithcode.com/paper/robust-reference-based-super-resolution-via',\n",
       " 'https://paperswithcode.com/paper/coarse-to-fine-embedded-patchmatch-and-multi',\n",
       " 'https://paperswithcode.com/paper/bart-denoising-sequence-to-sequence-pre',\n",
       " 'https://paperswithcode.com/paper/denoising-diffusion-probabilistic-models',\n",
       " 'https://paperswithcode.com/paper/noise2noise-learning-image-restoration',\n",
       " 'https://paperswithcode.com/paper/image-restoration-using-convolutional-auto',\n",
       " 'https://paperswithcode.com/paper/learning-to-see-in-the-dark',\n",
       " 'https://paperswithcode.com/paper/beyond-a-gaussian-denoiser-residual-learning',\n",
       " 'https://paperswithcode.com/paper/deep-image-prior',\n",
       " 'https://paperswithcode.com/paper/learning-enriched-features-for-real-image',\n",
       " 'https://paperswithcode.com/paper/low-dose-ct-image-denoising-using-a',\n",
       " 'https://paperswithcode.com/paper/iterative-gaussianization-from-ica-to-random',\n",
       " 'https://paperswithcode.com/paper/image-restoration-using-convolutional-auto',\n",
       " 'https://paperswithcode.com/paper/learning-to-see-in-the-dark',\n",
       " 'https://paperswithcode.com/paper/beyond-a-gaussian-denoiser-residual-learning',\n",
       " 'https://paperswithcode.com/paper/deep-image-prior',\n",
       " 'https://paperswithcode.com/paper/learning-enriched-features-for-real-image',\n",
       " 'https://paperswithcode.com/paper/low-dose-ct-image-denoising-using-a',\n",
       " 'https://paperswithcode.com/paper/noise2void-learning-denoising-from-single',\n",
       " 'https://paperswithcode.com/paper/ffdnet-toward-a-fast-and-flexible-solution',\n",
       " 'https://paperswithcode.com/paper/multi-level-wavelet-cnn-for-image-restoration',\n",
       " 'https://paperswithcode.com/paper/cycleisp-real-image-restoration-via-improved',\n",
       " 'https://paperswithcode.com/paper/residual-dense-network-for-image-super',\n",
       " 'https://paperswithcode.com/paper/swinir-image-restoration-using-swin',\n",
       " 'https://paperswithcode.com/paper/restormer-efficient-transformer-for-high',\n",
       " 'https://paperswithcode.com/paper/real-image-denoising-with-feature-attention',\n",
       " 'https://paperswithcode.com/paper/learning-deep-cnn-denoiser-prior-for-image',\n",
       " 'https://paperswithcode.com/paper/memnet-a-persistent-memory-network-for-image',\n",
       " 'https://paperswithcode.com/paper/blind-universal-bayesian-image-denoising-with',\n",
       " 'https://paperswithcode.com/paper/pre-trained-image-processing-transformer',\n",
       " 'https://paperswithcode.com/paper/renoir-a-dataset-for-real-low-light-image',\n",
       " 'https://paperswithcode.com/paper/sublabel-accurate-convex-relaxation-of',\n",
       " 'https://paperswithcode.com/paper/sar2sar-a-self-supervised-despeckling',\n",
       " 'https://paperswithcode.com/paper/sar-image-despeckling-using-a-convolutional',\n",
       " 'https://paperswithcode.com/paper/learning-a-dilated-residual-network-for-sar',\n",
       " 'https://paperswithcode.com/paper/guided-patch-wise-nonlocal-sar-despeckling',\n",
       " 'https://paperswithcode.com/paper/sar-image-despeckling-by-deep-neural-networks',\n",
       " 'https://paperswithcode.com/paper/speckle2void-deep-self-supervised-sar',\n",
       " 'https://paperswithcode.com/paper/despeckling-sentinel-1-grd-images-by-deep',\n",
       " 'https://paperswithcode.com/paper/as-if-by-magic-self-supervised-training-of',\n",
       " 'https://paperswithcode.com/paper/sar-image-despeckling-using-continuous',\n",
       " 'https://paperswithcode.com/paper/transformer-based-sar-image-despeckling',\n",
       " 'https://paperswithcode.com/paper/swinir-image-restoration-using-swin',\n",
       " 'https://paperswithcode.com/paper/restormer-efficient-transformer-for-high',\n",
       " 'https://paperswithcode.com/paper/index-network',\n",
       " 'https://paperswithcode.com/paper/low-weight-and-learnable-image-denoising',\n",
       " 'https://paperswithcode.com/paper/simple-online-and-realtime-tracking-with-a',\n",
       " 'https://paperswithcode.com/paper/a-simple-baseline-for-multi-object-tracking',\n",
       " 'https://paperswithcode.com/paper/towards-real-time-multi-object-tracking',\n",
       " 'https://paperswithcode.com/paper/re3-real-time-recurrent-regression-networks',\n",
       " 'https://paperswithcode.com/paper/mot16-a-benchmark-for-multi-object-tracking',\n",
       " 'https://paperswithcode.com/paper/center-based-3d-object-detection-and-tracking',\n",
       " 'https://paperswithcode.com/paper/fully-convolutional-siamese-networks-for-1',\n",
       " 'https://paperswithcode.com/paper/tracking-without-bells-and-whistles',\n",
       " 'https://paperswithcode.com/paper/bytetrack-multi-object-tracking-by-1',\n",
       " 'https://paperswithcode.com/paper/dcfnet-discriminant-correlation-filters',\n",
       " 'https://paperswithcode.com/paper/drop-an-octave-reducing-spatial-redundancy-in',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and',\n",
       " 'https://paperswithcode.com/paper/temporal-segment-networks-towards-good',\n",
       " 'https://paperswithcode.com/paper/a-closer-look-at-spatiotemporal-convolutions',\n",
       " 'https://paperswithcode.com/paper/the-kinetics-human-action-video-dataset',\n",
       " 'https://paperswithcode.com/paper/video-swin-transformer',\n",
       " 'https://paperswithcode.com/paper/temporal-shift-module-for-efficient-video',\n",
       " 'https://paperswithcode.com/paper/slowfast-networks-for-video-recognition',\n",
       " 'https://paperswithcode.com/paper/is-space-time-attention-all-you-need-for',\n",
       " 'https://paperswithcode.com/paper/video-swin-transformer',\n",
       " 'https://paperswithcode.com/paper/temporal-shift-module-for-efficient-video',\n",
       " 'https://paperswithcode.com/paper/is-space-time-attention-all-you-need-for',\n",
       " 'https://paperswithcode.com/paper/representation-flow-for-action-recognition',\n",
       " 'https://paperswithcode.com/paper/video-instance-segmentation',\n",
       " 'https://paperswithcode.com/paper/ts-lstm-and-temporal-inception-exploiting',\n",
       " 'https://paperswithcode.com/paper/learnable-pooling-with-context-gating-for',\n",
       " 'https://paperswithcode.com/paper/long-term-feature-banks-for-detailed-video',\n",
       " 'https://paperswithcode.com/paper/temporal-interlacing-network',\n",
       " 'https://paperswithcode.com/paper/ava-a-video-dataset-of-spatio-temporally',\n",
       " 'https://paperswithcode.com/paper/premvos-proposal-generation-refinement-and',\n",
       " 'https://paperswithcode.com/paper/rethinking-self-supervised-correspondence',\n",
       " 'https://paperswithcode.com/paper/lucid-data-dreaming-for-video-object',\n",
       " 'https://paperswithcode.com/paper/youtube-vos-sequence-to-sequence-video-object',\n",
       " 'https://paperswithcode.com/paper/interactive-video-object-segmentation-using',\n",
       " 'https://paperswithcode.com/paper/one-shot-video-object-segmentation',\n",
       " 'https://paperswithcode.com/paper/video-object-segmentation-with-re',\n",
       " 'https://paperswithcode.com/paper/fast-online-object-tracking-and-segmentation',\n",
       " 'https://paperswithcode.com/paper/feelvos-fast-end-to-end-embedding-learning',\n",
       " 'https://paperswithcode.com/paper/video-object-segmentation-using-space-time',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/group-normalization',\n",
       " 'https://paperswithcode.com/paper/learning-representations-from-eeg-with-deep',\n",
       " 'https://paperswithcode.com/paper/video-swin-transformer',\n",
       " 'https://paperswithcode.com/paper/is-space-time-attention-all-you-need-for',\n",
       " 'https://paperswithcode.com/paper/temporal-segment-networks-for-action',\n",
       " 'https://paperswithcode.com/paper/would-mega-scale-datasets-further-enhance',\n",
       " 'https://paperswithcode.com/paper/x3d-expanding-architectures-for-efficient',\n",
       " 'https://paperswithcode.com/paper/two-stream-convolutional-networks-for-action',\n",
       " 'https://paperswithcode.com/paper/youtube-8m-a-large-scale-video-classification',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/language-models-are-few-shot-learners',\n",
       " 'https://paperswithcode.com/paper/matching-networks-for-one-shot-learning',\n",
       " 'https://paperswithcode.com/paper/on-first-order-meta-learning-algorithms',\n",
       " 'https://paperswithcode.com/paper/learning-to-compare-relation-network-for-few',\n",
       " 'https://paperswithcode.com/paper/how-to-train-your-maml',\n",
       " 'https://paperswithcode.com/paper/meta-sgd-learning-to-learn-quickly-for-few',\n",
       " 'https://paperswithcode.com/paper/meta-learning-with-differentiable-convex',\n",
       " 'https://paperswithcode.com/paper/compact-bilinear-pooling',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/matching-networks-for-one-shot-learning',\n",
       " 'https://paperswithcode.com/paper/learning-transferable-visual-models-from',\n",
       " 'https://paperswithcode.com/paper/on-first-order-meta-learning-algorithms',\n",
       " 'https://paperswithcode.com/paper/meta-dataset-a-dataset-of-datasets-for',\n",
       " 'https://paperswithcode.com/paper/learning-to-compare-relation-network-for-few',\n",
       " 'https://paperswithcode.com/paper/how-to-train-your-maml',\n",
       " 'https://paperswithcode.com/paper/meta-learning-with-differentiable-convex',\n",
       " 'https://paperswithcode.com/paper/simpleshot-revisiting-nearest-neighbor',\n",
       " 'https://paperswithcode.com/paper/model-agnostic-meta-learning-for-fast',\n",
       " 'https://paperswithcode.com/paper/prototypical-networks-for-few-shot-learning',\n",
       " 'https://paperswithcode.com/paper/matching-networks-for-one-shot-learning',\n",
       " 'https://paperswithcode.com/paper/one-shot-learning-with-memory-augmented',\n",
       " 'https://paperswithcode.com/paper/siamese-neural-networks-for-one-shot-image',\n",
       " 'https://paperswithcode.com/paper/the-omniglot-challenge-a-3-year-progress',\n",
       " 'https://paperswithcode.com/paper/few-shot-adversarial-learning-of-realistic',\n",
       " 'https://paperswithcode.com/paper/one-shot-learning-for-semantic-segmentation',\n",
       " 'https://paperswithcode.com/paper/dynamic-few-shot-visual-learning-without',\n",
       " 'https://paperswithcode.com/paper/less-than-one-shot-learning-learning-n',\n",
       " 'https://paperswithcode.com/paper/panet-few-shot-image-semantic-segmentation',\n",
       " 'https://paperswithcode.com/paper/prior-guided-feature-enrichment-network-for',\n",
       " 'https://paperswithcode.com/paper/part-aware-prototype-network-for-few-shot',\n",
       " 'https://paperswithcode.com/paper/self-supervision-with-superpixels-training',\n",
       " 'https://paperswithcode.com/paper/few-shot-segmentation-without-meta-learning-a',\n",
       " 'https://paperswithcode.com/paper/few-shot-segmentation-via-cycle-consistent',\n",
       " 'https://paperswithcode.com/paper/cost-aggregation-is-all-you-need-for-few-shot',\n",
       " 'https://paperswithcode.com/paper/a-dense-subgraph-based-algorithm-for-compact',\n",
       " 'https://paperswithcode.com/paper/sg-one-similarity-guidance-network-for-one',\n",
       " 'https://paperswithcode.com/paper/few-shot-3d-multi-modal-medical-image',\n",
       " 'https://paperswithcode.com/paper/self-supervised-learning-for-few-shot-image',\n",
       " 'https://paperswithcode.com/paper/cross-domain-few-shot-learning-by-1',\n",
       " 'https://paperswithcode.com/paper/shallow-bayesian-meta-learning-for-real-world',\n",
       " 'https://paperswithcode.com/paper/improving-task-adaptation-for-cross-domain',\n",
       " 'https://paperswithcode.com/paper/on-label-efficient-computer-vision-building',\n",
       " 'https://paperswithcode.com/paper/beyond-simple-meta-learning-multi-purpose',\n",
       " 'https://paperswithcode.com/paper/a-new-benchmark-for-evaluation-of-cross',\n",
       " 'https://paperswithcode.com/paper/cross-domain-few-shot-classification-via-1',\n",
       " 'https://paperswithcode.com/paper/cross-domain-few-shot-learning-with-meta-fine',\n",
       " 'https://paperswithcode.com/paper/a-transductive-multi-head-model-for-cross',\n",
       " 'https://paperswithcode.com/paper/a-neural-algorithm-of-artistic-style',\n",
       " 'https://paperswithcode.com/paper/unpaired-image-to-image-translation-using',\n",
       " 'https://paperswithcode.com/paper/perceptual-losses-for-real-time-style',\n",
       " 'https://paperswithcode.com/paper/arbitrary-style-transfer-in-real-time-with',\n",
       " 'https://paperswithcode.com/paper/deep-photo-style-transfer',\n",
       " 'https://paperswithcode.com/paper/instance-normalization-the-missing-ingredient',\n",
       " 'https://paperswithcode.com/paper/universal-style-transfer-via-feature',\n",
       " 'https://paperswithcode.com/paper/deep-feature-consistent-variational',\n",
       " 'https://paperswithcode.com/paper/exploring-the-structure-of-a-real-time',\n",
       " 'https://paperswithcode.com/paper/style-transfer-from-non-parallel-text-by',\n",
       " 'https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition',\n",
       " 'https://paperswithcode.com/paper/unpaired-image-to-image-translation-using',\n",
       " 'https://paperswithcode.com/paper/image-to-image-translation-with-conditional',\n",
       " 'https://paperswithcode.com/paper/stargan-unified-generative-adversarial',\n",
       " 'https://paperswithcode.com/paper/u-gat-it-unsupervised-generative-attentional',\n",
       " 'https://paperswithcode.com/paper/semantic-image-synthesis-with-spatially',\n",
       " 'https://paperswithcode.com/paper/high-resolution-image-synthesis-and-semantic',\n",
       " 'https://paperswithcode.com/paper/multimodal-unsupervised-image-to-image',\n",
       " 'https://paperswithcode.com/paper/everybody-dance-now',\n",
       " 'https://paperswithcode.com/paper/stargan-v2-diverse-image-synthesis-for',\n",
       " 'https://paperswithcode.com/paper/spherical-kernel-for-efficient-graph',\n",
       " 'https://paperswithcode.com/paper/3d-point-capsule-networks',\n",
       " 'https://paperswithcode.com/paper/point-transformer',\n",
       " 'https://paperswithcode.com/paper/learning-geometry-disentangled-representation',\n",
       " 'https://paperswithcode.com/paper/scenegraphfusion-incremental-3d-scene-graph',\n",
       " 'https://paperswithcode.com/paper/rotationnet-joint-object-categorization-and',\n",
       " 'https://paperswithcode.com/paper/octnet-learning-deep-3d-representations-at',\n",
       " 'https://paperswithcode.com/paper/scannet-richly-annotated-3d-reconstructions',\n",
       " 'https://paperswithcode.com/paper/learning-a-hierarchical-latent-variable-model',\n",
       " 'https://paperswithcode.com/paper/o-cnn-octree-based-convolutional-neural',\n",
       " 'https://paperswithcode.com/paper/a-self-ensembling-framework-for-semi',\n",
       " 'https://paperswithcode.com/paper/a-simple-framework-for-contrastive-learning',\n",
       " 'https://paperswithcode.com/paper/momentum-contrast-for-unsupervised-visual',\n",
       " 'https://paperswithcode.com/paper/improved-baselines-with-momentum-contrastive',\n",
       " 'https://paperswithcode.com/paper/supervised-contrastive-learning',\n",
       " 'https://paperswithcode.com/paper/unsupervised-learning-of-visual-features-by',\n",
       " 'https://paperswithcode.com/paper/simcse-simple-contrastive-learning-of',\n",
       " 'https://paperswithcode.com/paper/contrastive-learning-for-unpaired-image-to',\n",
       " 'https://paperswithcode.com/paper/contrastive-multiview-coding',\n",
       " 'https://paperswithcode.com/paper/propagate-yourself-exploring-pixel-level',\n",
       " 'https://paperswithcode.com/paper/on-contrastive-learning-for-likelihood-free',\n",
       " 'https://paperswithcode.com/paper/inductive-relation-prediction-on-knowledge',\n",
       " 'https://paperswithcode.com/paper/learning-hierarchy-aware-knowledge-graph',\n",
       " 'https://paperswithcode.com/paper/nscaching-simple-and-efficient-negative',\n",
       " 'https://paperswithcode.com/paper/rotate-knowledge-graph-embedding-by',\n",
       " 'https://paperswithcode.com/paper/multi-task-feature-learning-for-knowledge',\n",
       " 'https://paperswithcode.com/paper/knowledge-graph-embedding-for',\n",
       " 'https://paperswithcode.com/paper/neural-recurrent-structure-search-for',\n",
       " 'https://paperswithcode.com/paper/kbgan-adversarial-learning-for-knowledge',\n",
       " 'https://paperswithcode.com/paper/autokge-searching-scoring-functions-for',\n",
       " 'https://paperswithcode.com/paper/efficient-relation-aware-scoring-function',\n",
       " 'https://paperswithcode.com/paper/can-spatiotemporal-3d-cnns-retrace-the',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and',\n",
       " 'https://paperswithcode.com/paper/spatial-temporal-graph-convolutional-networks-1',\n",
       " 'https://paperswithcode.com/paper/grad-cam-improved-visual-explanations-for',\n",
       " 'https://paperswithcode.com/paper/temporal-segment-networks-towards-good',\n",
       " 'https://paperswithcode.com/paper/cider-consensus-based-image-description',\n",
       " 'https://paperswithcode.com/paper/learning-spatiotemporal-features-with-3d',\n",
       " 'https://paperswithcode.com/paper/a-closer-look-at-spatiotemporal-convolutions',\n",
       " 'https://paperswithcode.com/paper/bmn-boundary-matching-network-for-temporal',\n",
       " 'https://paperswithcode.com/paper/multivariate-lstm-fcns-for-time-series',\n",
       " 'https://paperswithcode.com/paper/real-world-anomaly-detection-in-surveillance',\n",
       " 'https://paperswithcode.com/paper/representation-flow-for-action-recognition',\n",
       " 'https://paperswithcode.com/paper/ts-lstm-and-temporal-inception-exploiting',\n",
       " 'https://paperswithcode.com/paper/deep-residual-bidir-lstm-for-human-activity',\n",
       " 'https://paperswithcode.com/paper/im2flow-motion-hallucination-from-static',\n",
       " 'https://paperswithcode.com/paper/temporal-relational-reasoning-in-videos',\n",
       " 'https://paperswithcode.com/paper/fine-grained-activity-recognition-in-baseball',\n",
       " 'https://paperswithcode.com/paper/large-scale-weakly-supervised-pre-training',\n",
       " 'https://paperswithcode.com/paper/seco-exploring-sequence-supervision-for',\n",
       " 'https://paperswithcode.com/paper/spatial-temporal-graph-convolutional-networks-1',\n",
       " 'https://paperswithcode.com/paper/temporal-segment-networks-towards-good',\n",
       " 'https://paperswithcode.com/paper/moments-in-time-dataset-one-million-videos',\n",
       " 'https://paperswithcode.com/paper/assemblenet-searching-for-multi-stream-neural',\n",
       " 'https://paperswithcode.com/paper/gimme-signals-discriminative-signal-encoding',\n",
       " 'https://paperswithcode.com/paper/interpretable-3d-human-action-analysis-with',\n",
       " 'https://paperswithcode.com/paper/cross-modal-learning-by-hallucinating-missing',\n",
       " 'https://paperswithcode.com/paper/190412602',\n",
       " 'https://paperswithcode.com/paper/bayesian-hierarchical-dynamic-model-for-human',\n",
       " 'https://paperswithcode.com/paper/distilling-audio-visual-knowledge-by',\n",
       " 'https://paperswithcode.com/paper/long-term-feature-banks-for-detailed-video',\n",
       " 'https://paperswithcode.com/paper/large-scale-weakly-supervised-pre-training',\n",
       " 'https://paperswithcode.com/paper/what-would-you-expect-anticipating-egocentric',\n",
       " 'https://paperswithcode.com/paper/integrating-human-gaze-into-attention-for',\n",
       " 'https://paperswithcode.com/paper/first-person-hand-action-benchmark-with-rgb-d',\n",
       " 'https://paperswithcode.com/paper/a-correlation-based-feature-representation',\n",
       " 'https://paperswithcode.com/paper/attention-is-all-we-need-nailing-down-object',\n",
       " 'https://paperswithcode.com/paper/lsta-long-short-term-attention-for-egocentric',\n",
       " 'https://paperswithcode.com/paper/epic-fusion-audio-visual-temporal-binding-for',\n",
       " 'https://paperswithcode.com/paper/ego-exo-transferring-visual-representations',\n",
       " 'https://paperswithcode.com/paper/learning-actor-relation-graphs-for-group',\n",
       " 'https://paperswithcode.com/paper/revisiting-skeleton-based-action-recognition',\n",
       " 'https://paperswithcode.com/paper/spatio-temporal-dynamic-inference-network-for',\n",
       " 'https://paperswithcode.com/paper/a-hierarchical-deep-temporal-model-for-group',\n",
       " 'https://paperswithcode.com/paper/hierarchical-deep-temporal-models-for-group',\n",
       " 'https://paperswithcode.com/paper/sbgar-semantics-based-group-activity',\n",
       " 'https://paperswithcode.com/paper/hierarchical-relational-networks-for-group',\n",
       " 'https://paperswithcode.com/paper/video-understanding-based-on-human-action-and',\n",
       " 'https://paperswithcode.com/paper/learning-group-activities-from-skeletons',\n",
       " 'https://paperswithcode.com/paper/groupformer-group-activity-recognition-with',\n",
       " 'https://paperswithcode.com/paper/deepwalk-online-learning-of-social',\n",
       " 'https://paperswithcode.com/paper/unsupervised-anomaly-detection-with',\n",
       " 'https://paperswithcode.com/paper/a-baseline-for-detecting-misclassified-and',\n",
       " 'https://paperswithcode.com/paper/mura-large-dataset-for-abnormality-detection',\n",
       " 'https://paperswithcode.com/paper/padim-a-patch-distribution-modeling-framework',\n",
       " 'https://paperswithcode.com/paper/towards-total-recall-in-industrial-anomaly',\n",
       " 'https://paperswithcode.com/paper/ganomaly-semi-supervised-anomaly-detection',\n",
       " 'https://paperswithcode.com/paper/unsupervised-anomaly-detection-via',\n",
       " 'https://paperswithcode.com/paper/detecting-spacecraft-anomalies-using-lstms',\n",
       " 'https://paperswithcode.com/paper/real-world-anomaly-detection-in-surveillance',\n",
       " 'https://paperswithcode.com/paper/unsupervised-anomaly-detection-with',\n",
       " 'https://paperswithcode.com/paper/padim-a-patch-distribution-modeling-framework',\n",
       " 'https://paperswithcode.com/paper/unsupervised-anomaly-detection-via',\n",
       " 'https://paperswithcode.com/paper/band-selection-with-higher-order-multivariate',\n",
       " 'https://paperswithcode.com/paper/a-deep-neural-network-for-unsupervised',\n",
       " 'https://paperswithcode.com/paper/student-teacher-feature-pyramid-matching-for',\n",
       " 'https://paperswithcode.com/paper/memorizing-normality-to-detect-anomaly-memory',\n",
       " 'https://paperswithcode.com/paper/fastflow-unsupervised-anomaly-detection-and',\n",
       " 'https://paperswithcode.com/paper/using-self-supervised-learning-can-improve',\n",
       " 'https://paperswithcode.com/paper/uninformed-students-student-teacher-anomaly',\n",
       " 'https://paperswithcode.com/paper/real-world-anomaly-detection-in-surveillance',\n",
       " 'https://paperswithcode.com/paper/weakly-supervised-video-anomaly-detection',\n",
       " 'https://paperswithcode.com/paper/learning-memory-guided-normality-for-anomaly',\n",
       " 'https://paperswithcode.com/paper/abnormal-event-detection-on-bmtt-pets-2017',\n",
       " 'https://paperswithcode.com/paper/007-democratically-finding-the-cause-of',\n",
       " 'https://paperswithcode.com/paper/mist-multiple-instance-spatial-transformer',\n",
       " 'https://paperswithcode.com/paper/graph-convolutional-label-noise-cleaner-train',\n",
       " 'https://paperswithcode.com/paper/anomaly-detection-in-video-sequence-with',\n",
       " 'https://paperswithcode.com/paper/hybrid-deep-network-for-anomaly-detection',\n",
       " 'https://paperswithcode.com/paper/multiple-instance-based-video-anomaly',\n",
       " 'https://paperswithcode.com/paper/real-world-anomaly-detection-in-surveillance',\n",
       " 'https://paperswithcode.com/paper/abnormal-event-detection-in-videos-using',\n",
       " 'https://paperswithcode.com/paper/learning-temporal-regularity-in-video',\n",
       " 'https://paperswithcode.com/paper/a-scene-agnostic-framework-with-adversarial',\n",
       " 'https://paperswithcode.com/paper/abnormal-event-detection-on-bmtt-pets-2017',\n",
       " 'https://paperswithcode.com/paper/generative-neural-networks-for-anomaly',\n",
       " 'https://paperswithcode.com/paper/object-centric-auto-encoders-and-dummy',\n",
       " 'https://paperswithcode.com/paper/weakly-and-partially-supervised-learning',\n",
       " 'https://paperswithcode.com/paper/iterative-weak-self-supervised-classification',\n",
       " 'https://paperswithcode.com/paper/learnable-locality-sensitive-hashing-for',\n",
       " 'https://paperswithcode.com/paper/iterative-weak-self-supervised-classification',\n",
       " 'https://paperswithcode.com/paper/self-taught-semi-supervised-anomaly-detection',\n",
       " 'https://paperswithcode.com/paper/hop-count-based-self-supervised-anomaly',\n",
       " 'https://paperswithcode.com/paper/self-supervised-out-of-distribution-detection-1',\n",
       " 'https://paperswithcode.com/paper/self-supervised-anomaly-detection-by-self',\n",
       " 'https://paperswithcode.com/paper/facenet-a-unified-embedding-for-face',\n",
       " 'https://paperswithcode.com/paper/arcface-additive-angular-margin-loss-for-deep',\n",
       " 'https://paperswithcode.com/paper/vggface2-a-dataset-for-recognising-faces',\n",
       " 'https://paperswithcode.com/paper/sphereface-deep-hypersphere-embedding-for',\n",
       " 'https://paperswithcode.com/paper/learning-face-representation-from-scratch',\n",
       " 'https://paperswithcode.com/paper/ms-celeb-1m-a-dataset-and-benchmark-for-large',\n",
       " 'https://paperswithcode.com/paper/circle-loss-a-unified-perspective-of-pair',\n",
       " 'https://paperswithcode.com/paper/repmlp-re-parameterizing-convolutions-into',\n",
       " 'https://paperswithcode.com/paper/can-we-still-avoid-automatic-face-detection',\n",
       " 'https://paperswithcode.com/paper/cosface-large-margin-cosine-loss-for-deep',\n",
       " 'https://paperswithcode.com/paper/190500641',\n",
       " 'https://paperswithcode.com/paper/joint-face-detection-and-alignment-using',\n",
       " 'https://paperswithcode.com/paper/finding-tiny-faces',\n",
       " 'https://paperswithcode.com/paper/real-time-convolutional-neural-networks-for',\n",
       " 'https://paperswithcode.com/paper/lffd-a-light-and-fast-face-detector-for-edge',\n",
       " 'https://paperswithcode.com/paper/blazeface-sub-millisecond-neural-face',\n",
       " 'https://paperswithcode.com/paper/object-detection-with-pixel-intensity',\n",
       " 'https://paperswithcode.com/paper/can-we-still-avoid-automatic-face-detection',\n",
       " 'https://paperswithcode.com/paper/faceboxes-a-cpu-real-time-face-detector-with',\n",
       " 'https://paperswithcode.com/paper/midv-500-a-dataset-for-identity-documents',\n",
       " 'https://paperswithcode.com/paper/facenet-a-unified-embedding-for-face',\n",
       " 'https://paperswithcode.com/paper/arcface-additive-angular-margin-loss-for-deep',\n",
       " 'https://paperswithcode.com/paper/190500641',\n",
       " 'https://paperswithcode.com/paper/vggface2-a-dataset-for-recognising-faces',\n",
       " 'https://paperswithcode.com/paper/mobilefacenets-efficient-cnns-for-accurate',\n",
       " 'https://paperswithcode.com/paper/sphereface-deep-hypersphere-embedding-for',\n",
       " 'https://paperswithcode.com/paper/additive-margin-softmax-for-face-verification',\n",
       " 'https://paperswithcode.com/paper/circle-loss-a-unified-perspective-of-pair',\n",
       " 'https://paperswithcode.com/paper/cosface-large-margin-cosine-loss-for-deep',\n",
       " 'https://paperswithcode.com/paper/a-light-cnn-for-deep-face-representation-with',\n",
       " 'https://paperswithcode.com/paper/joint-face-detection-and-alignment-using',\n",
       " 'https://paperswithcode.com/paper/high-resolution-representations-for-labeling',\n",
       " 'https://paperswithcode.com/paper/pfld-a-practical-facial-landmark-detector',\n",
       " 'https://paperswithcode.com/paper/how-far-are-we-from-solving-the-2d-3d-face',\n",
       " 'https://paperswithcode.com/paper/fine-grained-head-pose-estimation-without',\n",
       " 'https://paperswithcode.com/paper/learning-a-model-of-facial-shape-and',\n",
       " 'https://paperswithcode.com/paper/adaptive-wing-loss-for-robust-face-alignment',\n",
       " 'https://paperswithcode.com/paper/wing-loss-for-robust-facial-landmark',\n",
       " 'https://paperswithcode.com/paper/joint-3d-face-reconstruction-and-dense',\n",
       " 'https://paperswithcode.com/paper/retinaface-single-shot-multi-level-face',\n",
       " 'https://paperswithcode.com/paper/challenges-in-representation-learning-a',\n",
       " 'https://paperswithcode.com/paper/training-deep-networks-for-facial-expression',\n",
       " 'https://paperswithcode.com/paper/deep-facial-expression-recognition-a-survey',\n",
       " 'https://paperswithcode.com/paper/dexpression-deep-convolutional-neural-network',\n",
       " 'https://paperswithcode.com/paper/facial-motion-prior-networks-for-facial',\n",
       " 'https://paperswithcode.com/paper/engagement-recognition-using-deep-learning',\n",
       " 'https://paperswithcode.com/paper/greedy-search-for-descriptive-spatial-face',\n",
       " 'https://paperswithcode.com/paper/convolutional-neural-networks-for-facial',\n",
       " 'https://paperswithcode.com/paper/microexpnet-an-extremely-small-and-fast-model',\n",
       " 'https://paperswithcode.com/paper/a-compact-embedding-for-facial-expression',\n",
       " 'https://paperswithcode.com/paper/can-spatiotemporal-3d-cnns-retrace-the',\n",
       " 'https://paperswithcode.com/paper/non-local-neural-networks',\n",
       " 'https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and',\n",
       " 'https://paperswithcode.com/paper/spatial-temporal-graph-convolutional-networks-1',\n",
       " 'https://paperswithcode.com/paper/grad-cam-improved-visual-explanations-for',\n",
       " 'https://paperswithcode.com/paper/temporal-segment-networks-towards-good',\n",
       " 'https://paperswithcode.com/paper/cider-consensus-based-image-description',\n",
       " 'https://paperswithcode.com/paper/learning-spatiotemporal-features-with-3d',\n",
       " 'https://paperswithcode.com/paper/a-closer-look-at-spatiotemporal-convolutions',\n",
       " 'https://paperswithcode.com/paper/bmn-boundary-matching-network-for-temporal',\n",
       " 'https://paperswithcode.com/paper/pointnet-deep-learning-on-point-sets-for-3d',\n",
       " 'https://paperswithcode.com/paper/graph-attention-networks',\n",
       " 'https://paperswithcode.com/paper/semi-supervised-classification-with-graph',\n",
       " 'https://paperswithcode.com/paper/quo-vadis-action-recognition-a-new-model-and',\n",
       " 'https://paperswithcode.com/paper/spatial-temporal-graph-convolutional-networks-1',\n",
       " 'https://paperswithcode.com/paper/independently-recurrent-neural-network-indrnn',\n",
       " 'https://paperswithcode.com/paper/ucf101-a-dataset-of-101-human-actions-classes',\n",
       " 'https://paperswithcode.com/paper/flownet-20-evolution-of-optical-flow',\n",
       " 'https://paperswithcode.com/paper/temporal-convolutional-networks-for-action',\n",
       " 'https://paperswithcode.com/paper/co-occurrence-feature-learning-from-skeleton',\n",
       " 'https://paperswithcode.com/paper/hide-and-seek-forcing-a-network-to-be',\n",
       " 'https://paperswithcode.com/paper/weakly-supervised-action-localization-by',\n",
       " 'https://paperswithcode.com/paper/untrimmednets-for-weakly-supervised-action',\n",
       " 'https://paperswithcode.com/paper/guess-where-actor-supervision-for',\n",
       " 'https://paperswithcode.com/paper/background-suppression-network-for-weakly',\n",
       " 'https://paperswithcode.com/paper/background-modeling-via-uncertainty',\n",
       " 'https://paperswithcode.com/paper/adversarial-background-aware-loss-for-weakly',\n",
       " 'https://paperswithcode.com/paper/acm-net-action-context-modeling-network-for',\n",
       " 'https://paperswithcode.com/paper/w-talc-weakly-supervised-temporal-activity',\n",
       " 'https://paperswithcode.com/paper/refineloc-iterative-refinement-for-weakly',\n",
       " 'https://paperswithcode.com/paper/weakly-supervised-action-localization-by',\n",
       " 'https://paperswithcode.com/paper/background-suppression-network-for-weakly',\n",
       " 'https://paperswithcode.com/paper/background-modeling-via-uncertainty',\n",
       " 'https://paperswithcode.com/paper/adversarial-background-aware-loss-for-weakly',\n",
       " 'https://paperswithcode.com/paper/acm-net-action-context-modeling-network-for',\n",
       " 'https://paperswithcode.com/paper/autoloc-weakly-supervised-temporal-action',\n",
       " 'https://paperswithcode.com/paper/refineloc-iterative-refinement-for-weakly',\n",
       " 'https://paperswithcode.com/paper/completeness-modeling-and-context-separation',\n",
       " 'https://paperswithcode.com/paper/3c-net-category-count-and-center-loss-for',\n",
       " 'https://paperswithcode.com/paper/weakly-supervised-temporal-action-1',\n",
       " 'https://paperswithcode.com/paper/grad-cam-improved-visual-explanations-for',\n",
       " 'https://paperswithcode.com/paper/unsupervised-learning-of-object-keypoints-for',\n",
       " 'https://paperswithcode.com/paper/reconstructing-undersampled-photoacoustic',\n",
       " 'https://paperswithcode.com/paper/ntu-rgbd-a-large-scale-dataset-for-3d-human',\n",
       " 'https://paperswithcode.com/paper/interpretable-3d-human-action-analysis-with',\n",
       " 'https://paperswithcode.com/paper/investigation-of-different-skeleton-features',\n",
       " 'https://paperswithcode.com/paper/recognizing-involuntary-actions-from-3d',\n",
       " 'https://paperswithcode.com/paper/fisherposes-for-human-action-recognition',\n",
       " 'https://paperswithcode.com/paper/temporal-transformer-networks-joint-learning-1',\n",
       " 'https://paperswithcode.com/paper/skelemotion-a-new-representation-of-skeleton',\n",
       " 'https://paperswithcode.com/paper/a-simple-framework-for-contrastive-learning',\n",
       " 'https://paperswithcode.com/paper/albert-a-lite-bert-for-self-supervised',\n",
       " 'https://paperswithcode.com/paper/bootstrap-your-own-latent-a-new-approach-to',\n",
       " 'https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision',\n",
       " 'https://paperswithcode.com/paper/covid-ct-dataset-a-ct-scan-dataset-about',\n",
       " 'https://paperswithcode.com/paper/tabnet-attentive-interpretable-tabular',\n",
       " 'https://paperswithcode.com/paper/supervised-contrastive-learning',\n",
       " 'https://paperswithcode.com/paper/wav2vec-2-0-a-framework-for-self-supervised',\n",
       " 'https://paperswithcode.com/paper/emerging-properties-in-self-supervised-vision',\n",
       " 'https://paperswithcode.com/paper/digging-into-self-supervised-monocular-depth',\n",
       " 'https://paperswithcode.com/paper/pointcontrast-unsupervised-pre-training-for',\n",
       " 'https://paperswithcode.com/paper/pre-training-by-completing-point-clouds',\n",
       " 'https://paperswithcode.com/paper/pos-bert-point-cloud-one-stage-bert-pre',\n",
       " 'https://paperswithcode.com/paper/high-quality-monocular-depth-estimation-via',\n",
       " 'https://paperswithcode.com/paper/deeper-depth-prediction-with-fully',\n",
       " 'https://paperswithcode.com/paper/unsupervised-monocular-depth-estimation-with',\n",
       " 'https://paperswithcode.com/paper/digging-into-self-supervised-monocular-depth',\n",
       " 'https://paperswithcode.com/paper/depth-prediction-without-the-sensors',\n",
       " 'https://paperswithcode.com/paper/vision-transformers-for-dense-prediction',\n",
       " 'https://paperswithcode.com/paper/factorized-attention-self-attention-with',\n",
       " 'https://paperswithcode.com/paper/what-uncertainties-do-we-need-in-bayesian',\n",
       " 'https://paperswithcode.com/paper/towards-robust-monocular-depth-estimation',\n",
       " 'https://paperswithcode.com/paper/from-big-to-small-multi-scale-local-planar']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title),len(url),len(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ba7933",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (675) does not match length of index (931)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2892/2898916538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pdf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (675) does not match length of index (931)"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=['title','url','pdf'])\n",
    "\n",
    "df['title']=title\n",
    "df['url']=url\n",
    "df['pdf']=pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#내용저장 csv\n",
    "df.to_csv(\"theory.csv\",header=True, index=False)\n",
    "df_theory=pd.read_csv('theory.csv')\n",
    "df_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f80373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os로 파일 다운로드\n",
    "pdf_url = df['pdf'].values.tolist()\n",
    "pdf_file = [i.split('/')[-1] for i in df['pdf'].values if 'arxiv' in i]\n",
    "\n",
    "print(f'전체 파일 수: {len(pdf_url)}')\n",
    "\n",
    "#enumerate -> index / for n, ( , ) = n=index, ( , )=tuple\n",
    "#start /b =>os background실행\n",
    "for n, (url, file) in enumerate(zip(pdf_url, pdf_file)):\n",
    "    print(n)\n",
    "    download_path = f'C:/Users/kimEn/Downloads/pdf_download'\n",
    "    os.system(f'curl \"{url}\" --output \"{download_path}/{file}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708638e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf text변환 / 다른 사이트 참고 ->  출처: https://koreapy.tistory.com/829\n",
    "def pdf_to_txt(pdf_file):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "   \n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(pdf_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    \n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,\n",
    "                                 caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    \n",
    "    text = retstr.getvalue()\n",
    "    \n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    pdf_txt=[]\n",
    "    pdf_txt.append(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오류제외 파일변환\n",
    "\n",
    "for i in tqdm(pdf_file):    \n",
    "    try:\n",
    "        text = pdf_to_txt(f'{download_path}/{i}')\n",
    "        txt_file_name = '.'.join(i.split('.')[:-1])\n",
    "        with open(f'{download_path}/txt/{txt_file_name}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "    except Exception as e:\n",
    "        print(e, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93eb750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48747e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d508a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ae4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 사이트 참고 -> 출처:\n",
    "\n",
    "def get_wordnet_pos(tagged_pos):\n",
    "    for pos in ['V', 'N', 'J', 'R']:\n",
    "        if tagged_pos.startswith(pos):\n",
    "            return pos.lower() if pos != 'J' else 'a'\n",
    "    return None\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "for txt_file in tqdm(glob('./Downloads/pdf_download2/txt/*.txt')):\n",
    "    with open(txt_file, encoding='utf-8') as f:\n",
    "        txt = f.read().lower().replace('-\\n', '')\n",
    "        \n",
    "        \n",
    "    # 토크나이저\n",
    "        re_tokenizer = RegexpTokenizer('[a-zA-Z]{2,}')\n",
    "\n",
    "        # 토큰화\n",
    "        word_tokens = re_tokenizer.tokenize(txt)\n",
    "\n",
    "        # 불용어(stopwords) 제거\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words.append('cid')\n",
    "        word_tokens = [w for w in word_tokens if w not in stop_words]\n",
    "\n",
    "        #stemmer = PorterStemmer()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        word_tokens = [stemmer.stem(w) for w in word_tokens]\n",
    "\n",
    "        word_tokens = pos_tag(word_tokens)\n",
    "        word_tokens = [(w, get_wordnet_pos(tag)) for w, tag in word_tokens if get_wordnet_pos(tag) != None]\n",
    "        word_tokens = [lemm.lemmatize(word, pos=tag) for word, tag in word_tokens]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e295994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "txt_title=[]\n",
    "for txt_file in tqdm(glob('./Downloads/pdf_download2/txt/*.txt')):\n",
    "    with open(txt_file, encoding='utf-8') as f:\n",
    "        #txt = f.read().lower().replace('-\\n', '')\n",
    "        #sentence=sent_tokenize(txt)\n",
    "        sentence=f.read().lower().replace('-\\n', '').replace('\\n', ' ').split('.')\n",
    "        txt_title.append(txt_file)\n",
    "        #print(os.system('os.curdir()')) #현재 디렉토리\n",
    "        print(os.path.basename(txt_file)) #파일명 추출\n",
    "\n",
    "#sentence가 들어있던 txt_title 불러오기: sentence를 사전으로 저장/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈도수 높은 단어 설명 문장 추출1+출처 표기(논문제목+이름)\n",
    "#lower 걸기\n",
    "#fileinput모듈로 대체\n",
    "#(cid:숫자)=글꼴 이름 제외, 수식 제외, pos tag\n",
    "\n",
    "import fileinput\n",
    "import string\n",
    "import re\n",
    "\n",
    "meaning={}\n",
    "#keywords=[x for x in FreqDist(word_tokens) if x.index()<1000]\n",
    "keywords=FreqDist(word_tokens)\n",
    "terminology=[]\n",
    "\n",
    "\n",
    "# with open(glob('./Downloads/pdf_download/txt/*.txt'), encoding='utf-8') as f:\n",
    "#     # replace_space(f)\n",
    "#     sentence=f.read().lower().split('.')\n",
    "for txt_file in tqdm(glob('./Downloads/pdf_download2/txt/*.txt')):\n",
    "    with open(txt_file, encoding='utf-8') as f:\n",
    "        #txt = f.read().lower().replace('-\\n', '')\n",
    "        #sentence=sent_tokenize(txt)\n",
    "        sentence=f.read().lower().replace('-\\n', '').replace('\\n', ' ').split('.')\n",
    "        txt_title=txt_file\n",
    "\n",
    "        \n",
    "for s in sentence:\n",
    "    for k in keywords:\n",
    "        \n",
    "        #word-token에서 verb만 일치하도록 변경\n",
    "        #if s.find(k)>0 and ((s.find('is')>0 and t[0] for t in tagged_list if t[1].startswith('V')) or (s.find('are')>0)):  \n",
    "        \n",
    "        if k in s and ' is ' in s and 'cid' not in s: \n",
    "            if s.isascii()==True:\n",
    "                tmp=[]\n",
    "                tmp.append(s)    \n",
    "                meaning[k]=s\n",
    "                #print(os.path.basename(txt_file))\n",
    "            \n",
    "\n",
    "\n",
    "          \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "#         for i in range(len(keywords[0])):\n",
    "#             if k[0].index(i)\n",
    "# #         if k[0][i].index() < k[0].index()\n",
    "#             terminology=[]\n",
    "print(meaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19c2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb261ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{f}가 제일먼저 나오는 text, 출처url\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "research=[]\n",
    "href=[]\n",
    "\n",
    "for n,f in enumerate(FreqDist(word_tokens)):\n",
    "    if n<100:\n",
    "        driver.get('https://www.google.com')\n",
    "        elem=driver.find_element(By.CLASS_NAME, 'gLFyf.gsfi')\n",
    "\n",
    "        # 검색\n",
    "        elem.clear()\n",
    "        elem.send_keys(f'what is {f} of deep learning')\n",
    "        driver.find_element(By.CLASS_NAME, 'gNO89b').submit()                   \n",
    "        \n",
    "        first_list=driver.find_elements(By.CLASS_NAME, 'yp1CPe.wDYxhc.NFQFxe.viOShc.LKPcQc')\n",
    "        href_list=driver.find_elements(By.CLASS_NAME, 'yp1CPe.wDYxhc.NFQFxe.viOShc.LKPcQc > div > div > div > div > div > div > a')\n",
    "            \n",
    "\n",
    "        for i in first_list:            \n",
    "            research.append(i.text)          \n",
    "            \n",
    "            print(i.text)\n",
    "            \n",
    "        #replace\n",
    "        \n",
    "            for i in href_list:           \n",
    "  \n",
    "                href.append(i.get_attribute('href'))\n",
    "                print(i.get_attribute('href'))\n",
    "    \n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c21349",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.google.com')\n",
    "\n",
    "\n",
    "for n,f in enumerate(FreqDist(word_tokens)):\n",
    "    if n<100:\n",
    "        driver.get('https://www.google.com')\n",
    "        elem=driver.find_element(By.CLASS_NAME, 'gLFyf.gsfi')\n",
    "\n",
    "        # 검색\n",
    "        elem.clear()\n",
    "        elem.send_keys(f'what is {f} of deep learning')\n",
    "        driver.find_element(By.CLASS_NAME, 'gNO89b').submit()\n",
    "#driver.find_element(By.ID, \"id_global_search_input\").send_keys(Keys.ENTER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스니펫 안나오는것 -> 관련질문\n",
    "\n",
    "#{f}가 제일먼저 나오는 text, 관련질문 맨 위에 있는 거 가져오기 ->클릭해야 보임\n",
    "#관련 내용 부분\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "\n",
    "\n",
    "for n,f in enumerate(FreqDist(word_tokens)):\n",
    "    if n<100:\n",
    "        driver.get('https://www.google.com')\n",
    "        elem=driver.find_element(By.CLASS_NAME, 'gLFyf.gsfi')\n",
    "\n",
    "        # 검색\n",
    "        elem.clear()\n",
    "        elem.send_keys(f'what is {f} of deep learning')\n",
    "        driver.find_element(By.CLASS_NAME, 'gNO89b').submit()\n",
    "        \n",
    "        mlist=driver.find_elements(By.CLASS_NAME, 'Wt5Tfe')\n",
    "        clist=driver.find_elements(By.CLASS_NAME, 'wQiwMc.ygGdYd.related-question-pair')\n",
    "        hreflist=driver.find_elements(By.CLASS_NAME, 'yuRUbf > a')\n",
    "\n",
    "\n",
    "        def click_question():\n",
    "            for n,c in enumerate(clist):\n",
    "                if n<5:\n",
    "                    c.click()\n",
    "            \n",
    "\n",
    "        click_question()\n",
    "\n",
    "        for i in mlist:\n",
    "             lines=mlist[0].text.split('관련')\n",
    "\n",
    "        #print(lines)\n",
    "        research=[]\n",
    "        research.append(lines[1].replace('질문','').replace('\\n',' '))\n",
    "        print(research)\n",
    "        # for n,i in enumerate(lines):\n",
    "        #     print(n,i+'\\n')\n",
    "\n",
    "        #replace\n",
    "        href=[]\n",
    "        for i in hreflist:\n",
    "            href.append(i.get_attribute('href'))\n",
    "\n",
    "        print(href[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74153b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구글번역기로 번역<>\n",
    "from googletrans import Translator\n",
    "\n",
    "Ttranslated={}\n",
    "\n",
    "# for i in meaning.values():\n",
    "    \n",
    "#     translator=Translator()\n",
    "#     result=translator.translate(i,src='en', dest='ko')\n",
    "#     #Ttranslated[meaning.keys()]=result\n",
    "#     print(i)\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "translator=Translator()\n",
    "result=translator.translate(research[0], src='en', dest='ko')\n",
    "# #Ttranslated[meaning.keys()]=result\n",
    "print(research[0])\n",
    "print(result.text)\n",
    "Ttranslated[research[0]]=result.text #번역 저장 어떻게 할 것인지\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meaning불러오기 / 없는거 search로 불러오기 / 빈도수 정렬\n",
    "\n",
    "for n,(x,y) in enumerate(meaning.items()):\n",
    "    print(n, x+':'+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv저장: df: title, url, pdf_url \n",
    "#df2: keywords, meaning, translate, meaning_url\n",
    "#df3: keywords, big_classification, middle_class, small_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a920886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(단어-분류)-(의미 번역-원문-출처) -> csv 저장\n",
    "import pandas as pd\n",
    "df2=pd.DataFrame(columns=['단어','설명','원문','출처'])\n",
    "\n",
    "df2['단어']=meaning.keys()\n",
    "df2['원문']=meaning.values()\n",
    "df2['설명']=Ttranslated\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e165d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distionary 성능향상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
