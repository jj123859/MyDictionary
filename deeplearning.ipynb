{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a41c2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "from konlpy.tag import Twitter\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tag import untag\n",
    "from nltk import Text\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import FreqDist\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs', {\n",
    "    \"download.default_directory\": \"C:/Users/kimEn/Desktop\", #Change default directory for downloads\n",
    "    \"download.prompt_for_download\": False, #To auto download the file\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "})\n",
    "driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "driver.get('https://paperswithcode.com/sota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85bf342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_first=[] \n",
    "url_to=driver.find_elements(By.CLASS_NAME,'col-md-12 > h4 > a')\n",
    "for url1 in url_to:\n",
    "    url_to_first.append(url1.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_url=[]\n",
    "see_all_url=[]\n",
    "\n",
    "for i in range(len(url_to_first)):\n",
    "    driver.get(url_to_first[i]) \n",
    "    \n",
    "    card_url_elem=driver.find_elements(By.CLASS_NAME,'card > a')\n",
    "    see_all_elem = driver.find_elements(By.CLASS_NAME,'sota-all-tasks > a')\n",
    "    \n",
    "    for c in card_url_elem:\n",
    "        if c.get_attribute('href') not in card_url:\n",
    "            card_url.append(c.get_attribute('href'))\n",
    "\n",
    "    for s in see_all_elem:          \n",
    "            see_all_url.append(s.get_attribute('href'))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d8b651",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/2600719284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msee_all_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msee_all_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcard_url_elem2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'card > a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcard_url_elem2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(see_all_url)):\n",
    "    driver.get(see_all_url[i])\n",
    "    card_url_elem2=driver.find_elements(By.CLASS_NAME,'card > a')\n",
    "\n",
    "    for c2 in card_url_elem2:\n",
    "        if c2.get_attribute('href') not in card_url:\n",
    "            card_url.append(c2.get_attribute('href'))\n",
    "\n",
    "save_url=card_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2440e79",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/3110430224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mTlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'col-lg-9.item-content > h1 > a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 논문 제목, 상세 url 수집\n",
    "# classname>css section\n",
    "import collections\n",
    "\n",
    "title = []\n",
    "url = []\n",
    "pdf=[]\n",
    "classification1=[]\n",
    "classification2=[]\n",
    "\n",
    "cla_dict=collections.defaultdict(list)\n",
    "pdf_cla_dict={}\n",
    "\n",
    "for i in range(len(card_url)): \n",
    "    driver.get(card_url[i])\n",
    "    \n",
    "    Tlist=driver.find_elements(By.CLASS_NAME,'col-lg-9.item-content > h1 > a')\n",
    "    classification1_elem=driver.find_elements(By.CLASS_NAME,'dataset-header > a')\n",
    "    classification2_elem=driver.find_elements(By.CLASS_NAME, 'artefact-header > h1')\n",
    "        \n",
    "        \n",
    "    for cla1 in classification1_elem:\n",
    "        cla_item=cla1.get_attribute('href').split('/')[-1].replace('-',' ')\n",
    "        classification1.append(cla_item)\n",
    "\n",
    "        for cla2 in classification2_elem:\n",
    "            classification2.append(cla2.text)\n",
    "            cla_dict[cla_item].append(cla2.text)\n",
    "            \n",
    "            \n",
    "    for i in Tlist:\n",
    "        if i.get_attribute not in url and i.text not in title: \n",
    "            title.append(i.text)\n",
    "            url.append(i.get_attribute('href'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f690663b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/1053577854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclassification2_elem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'artefact-header > h1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mTlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'col-lg-9.item-content > h1 > a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url_cla_dict={}\n",
    "\n",
    "for i in range(len(card_url)): \n",
    "    driver.get(card_url[i])\n",
    "    classification2_elem=driver.find_elements(By.CLASS_NAME, 'artefact-header > h1')\n",
    "    Tlist=driver.find_elements(By.CLASS_NAME,'col-lg-9.item-content > h1 > a')\n",
    "        \n",
    "    for cla2 in classification2_elem:\n",
    "        for i in Tlist:\n",
    "            url_cla_dict[i.text]=cla2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05e8367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_url 수집\n",
    "for i in range(len(url)):    \n",
    "        \n",
    "    driver.get(url[i])\n",
    "    pdf_url=driver.find_elements(By.CLASS_NAME,'badge.badge-light')[0].get_attribute('href')\n",
    "    \n",
    "    if pdf_url not in pdf:\n",
    "        pdf.append(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02ba7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['title','url','pdf'])\n",
    "\n",
    "df['title']=title\n",
    "df['url']=url\n",
    "df['pdf']=pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07c7bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>https://paperswithcode.com/paper/deep-residual...</td>\n",
       "      <td>https://arxiv.org/pdf/1512.03385v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Deep Convolutional Networks for Large-Sca...</td>\n",
       "      <td>https://paperswithcode.com/paper/very-deep-con...</td>\n",
       "      <td>https://arxiv.org/pdf/1409.1556v6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MobileNets: Efficient Convolutional Neural Net...</td>\n",
       "      <td>https://paperswithcode.com/paper/mobilenets-ef...</td>\n",
       "      <td>https://arxiv.org/pdf/1704.04861v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Densely Connected Convolutional Networks</td>\n",
       "      <td>https://paperswithcode.com/paper/densely-conne...</td>\n",
       "      <td>https://arxiv.org/pdf/1608.06993v5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSPNet: A New Backbone that can Enhance Learni...</td>\n",
       "      <td>https://paperswithcode.com/paper/cspnet-a-new-...</td>\n",
       "      <td>https://arxiv.org/pdf/1911.11929v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>A 64mW DNN-based Visual Navigation Engine for ...</td>\n",
       "      <td>https://paperswithcode.com/paper/a-64mw-dnn-ba...</td>\n",
       "      <td>https://arxiv.org/pdf/1805.01831v4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>A water-obstacle separation and refinement net...</td>\n",
       "      <td>https://paperswithcode.com/paper/a-water-obsta...</td>\n",
       "      <td>https://arxiv.org/pdf/2001.01921v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Socially Aware Motion Planning with Deep Reinf...</td>\n",
       "      <td>https://paperswithcode.com/paper/socially-awar...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.08862v2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Intention-Net: Integrating Planning and Deep L...</td>\n",
       "      <td>https://paperswithcode.com/paper/intention-net...</td>\n",
       "      <td>https://arxiv.org/pdf/1710.05627v2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Image Restoration Using Convolutional Auto-enc...</td>\n",
       "      <td>https://paperswithcode.com/paper/image-restora...</td>\n",
       "      <td>https://arxiv.org/pdf/1606.08921v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0         Deep Residual Learning for Image Recognition   \n",
       "1    Very Deep Convolutional Networks for Large-Sca...   \n",
       "2    MobileNets: Efficient Convolutional Neural Net...   \n",
       "3             Densely Connected Convolutional Networks   \n",
       "4    CSPNet: A New Backbone that can Enhance Learni...   \n",
       "..                                                 ...   \n",
       "355  A 64mW DNN-based Visual Navigation Engine for ...   \n",
       "356  A water-obstacle separation and refinement net...   \n",
       "357  Socially Aware Motion Planning with Deep Reinf...   \n",
       "358  Intention-Net: Integrating Planning and Deep L...   \n",
       "359  Image Restoration Using Convolutional Auto-enc...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://paperswithcode.com/paper/deep-residual...   \n",
       "1    https://paperswithcode.com/paper/very-deep-con...   \n",
       "2    https://paperswithcode.com/paper/mobilenets-ef...   \n",
       "3    https://paperswithcode.com/paper/densely-conne...   \n",
       "4    https://paperswithcode.com/paper/cspnet-a-new-...   \n",
       "..                                                 ...   \n",
       "355  https://paperswithcode.com/paper/a-64mw-dnn-ba...   \n",
       "356  https://paperswithcode.com/paper/a-water-obsta...   \n",
       "357  https://paperswithcode.com/paper/socially-awar...   \n",
       "358  https://paperswithcode.com/paper/intention-net...   \n",
       "359  https://paperswithcode.com/paper/image-restora...   \n",
       "\n",
       "                                        pdf  \n",
       "0    https://arxiv.org/pdf/1512.03385v1.pdf  \n",
       "1     https://arxiv.org/pdf/1409.1556v6.pdf  \n",
       "2    https://arxiv.org/pdf/1704.04861v1.pdf  \n",
       "3    https://arxiv.org/pdf/1608.06993v5.pdf  \n",
       "4    https://arxiv.org/pdf/1911.11929v1.pdf  \n",
       "..                                      ...  \n",
       "355  https://arxiv.org/pdf/1805.01831v4.pdf  \n",
       "356  https://arxiv.org/pdf/2001.01921v1.pdf  \n",
       "357  https://arxiv.org/pdf/1703.08862v2.pdf  \n",
       "358  https://arxiv.org/pdf/1710.05627v2.pdf  \n",
       "359  https://arxiv.org/pdf/1606.08921v3.pdf  \n",
       "\n",
       "[360 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#내용저장 csv\n",
    "df.to_csv(\"theory.csv\",header=True, index=False)\n",
    "df_theory=pd.read_csv('theory.csv')\n",
    "df_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05f80373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 파일 수: 360\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/3642870449.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdownload_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'C:/Users/kimEn/Downloads/pdf_download'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'curl \"{url}\" --output \"{download_path}/{file}\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#os로 파일 다운로드\n",
    "pdf_url = df['pdf'].values.tolist()\n",
    "pdf_file = [i.split('/')[-1] for i in df['pdf'].values if 'arxiv' in i]\n",
    "\n",
    "print(f'전체 파일 수: {len(pdf_url)}')\n",
    "\n",
    "#enumerate -> index / for n, ( , ) = n=index, ( , )=tuple\n",
    "#start /b =>os background실행\n",
    "for n, (url, file) in enumerate(zip(pdf_url, pdf_file)):\n",
    "    print(n)\n",
    "    download_path = f'C:/Users/kimEn/Downloads/pdf_download'\n",
    "    os.system(f'curl \"{url}\" --output \"{download_path}/{file}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c0b9ccf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f05e1a83eb940a9bdbefcc05ac24240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pdf_to_txt' is not defined 1512.03385v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1409.1556v6.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.04861v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1608.06993v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.11929v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1801.04381v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1610.02391v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.11946v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1512.00567v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2010.11929v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1503.02531v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.08962v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1910.01108v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.04558v6.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.11063v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.09813v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.07947v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.03928v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1909.10351v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.09717v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.03400v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.05175v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.04080v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2103.00020v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.02999v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.03096v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.06025v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1810.09502v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.03758v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.04623v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.04606v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1906.02845v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.12510v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2102.08248v7.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.02977v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.01316v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2106.09022v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1909.11480v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.11297v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.04005v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.09501v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.12877v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2105.03404v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2010.01412v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2103.00112v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1811.06965v5.pdf\n",
      "name 'pdf_to_txt' is not defined 2110.00476v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.01461v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1505.04597v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.06870v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1906.07155v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.00593v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.01355v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1511.00561v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.02611v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1706.05587v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1505.03540v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1709.00382v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.10508v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.00445v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1810.11654v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1901.04056v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1702.05970v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.02427v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.08403v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1906.03720v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.08955v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.12872v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.10152v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1901.02446v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.06815v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.06667v6.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.10821v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2106.13797v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.10194v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1706.02413v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.07368v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.08889v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.10275v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.02713v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.08755v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.11236v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.03653v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.10732v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.04628v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.05044v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1502.02734v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2101.11253v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1412.7144v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.10464v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.04581v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.01947v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.02767v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.08242v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.10934v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1708.02002v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1512.02325v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1506.01497v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1506.02640v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.08488v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.06396v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.11027v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.09664v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.06199v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.04244v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.00496v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.11275v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.05784v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.00557v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.09007v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.01169v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2008.00230v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.09569v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.11445v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2009.03075v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1807.09940v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.13168v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.07850v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.09070v7.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.08636v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.06781v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.02713v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.04901v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.11782v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2008.12134v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1505.07818v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.10467v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.07629v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.14165v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1409.7495v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1702.05464v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1807.09441v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.10349v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.00848v6.pdf\n",
      "name 'pdf_to_txt' is not defined 1310.1531v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.08565v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1607.01719v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.05424v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.02560v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.13256v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1608.06019v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.03243v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2106.04732v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.09412v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.04899v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1708.04552v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2111.06377v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2201.03545v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.02781v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.02893v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.12261v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.02497v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.09210v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1808.04205v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1811.07456v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.03699v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.07222v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.12230v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.07953v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.08546v6.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.02541v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.04914v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2104.03344v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.01130v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2104.04665v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2107.02067v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2107.11011v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.04958v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1701.07875v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.00028v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.10196v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.04948v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1706.08500v6.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.08318v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.03498v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.01164v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1605.05396v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.10593v7.pdf\n",
      "name 'pdf_to_txt' is not defined 1611.07004v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.09020v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.10830v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.07291v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.11585v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.04732v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1808.07371v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.01865v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.07723v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.03589v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1801.07892v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1901.00212v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.09661v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.10925v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.05600v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1607.07539v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2011.13456v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.09704v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1511.06434v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1610.09585v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1809.11096v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.06676v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.05328v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.05637v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.13457v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1807.09251v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2008.00951v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.10786v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2007.13332v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.10195v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2102.12593v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.08779v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.04297v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1801.01563v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.12848v6.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.06650v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1708.04896v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2004.11362v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.00397v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1708.04680v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1906.11172v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1809.06839v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1910.02190v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.05393v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1901.11196v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.06201v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.09460v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1709.01643v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1807.01554v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.04718v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.03752v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2011.06056v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.15699v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2104.08826v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2110.04361v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.09050v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.00676v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1611.05763v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1707.09835v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2104.08691v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1611.08050v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1602.00134v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.08008v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1603.06937v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1904.04514v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1902.09212v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.07919v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.07971v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.00434v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.01934v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.07064v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.02716v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.00595v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.01770v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.03826v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2008.13751v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2102.02808v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2106.03106v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2111.09881v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.05535v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1901.08971v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2006.07397v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1809.00888v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1909.12962v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.02877v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1811.00656v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.13458v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2001.00179v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1609.04802v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1603.08155v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1501.00092v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1707.02921v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1609.05158v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1809.00219v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.02735v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2003.03808v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1608.03981v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1905.03079v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.10137v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.04012v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2108.07938v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1801.07455v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1705.03098v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1701.00295v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1811.11742v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.07399v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.06903v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.02447v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.06584v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1907.00837v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.07809v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.06208v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1605.03170v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.01465v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.03453v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.05656v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1810.09381v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1711.08229v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.03917v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1802.09232v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.10462v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.04314v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.10357v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1811.12004v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.00137v5.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.07451v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1910.06278v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2107.08430v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.07695v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1612.01051v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.06604v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.07911v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1912.04838v7.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.03952v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1807.00412v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1705.05065v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.05465v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1705.08926v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.05620v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1705.09785v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1812.01097v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2101.06085v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1712.02294v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.09719v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1604.07316v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1803.10892v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2103.02440v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1509.09308v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1608.01230v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2005.04259v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1611.05418v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.10150v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1705.06640v4.pdf\n",
      "name 'pdf_to_txt' is not defined 1610.05949v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1910.02490v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1709.07492v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1610.06475v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1704.04664v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1903.01067v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1908.10349v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2002.06289v2.pdf\n",
      "name 'pdf_to_txt' is not defined 2008.05416v1.pdf\n",
      "name 'pdf_to_txt' is not defined 2010.09297v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1801.02805v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1911.00357v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1806.11430v3.pdf\n",
      "name 'pdf_to_txt' is not defined 2012.11717v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1804.00168v3.pdf\n",
      "name 'pdf_to_txt' is not defined 1805.01831v4.pdf\n",
      "name 'pdf_to_txt' is not defined 2001.01921v1.pdf\n",
      "name 'pdf_to_txt' is not defined 1703.08862v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1710.05627v2.pdf\n",
      "name 'pdf_to_txt' is not defined 1606.08921v3.pdf\n"
     ]
    }
   ],
   "source": [
    "#오류제외 파일변환\n",
    "\n",
    "for i in tqdm(pdf_file):    \n",
    "    try:\n",
    "        text = pdf_to_txt(f'{download_path}/{i}')\n",
    "        txt_file_name = '.'.join(i.split('.')[:-1])\n",
    "        with open(f'{download_path}/txt/{txt_file_name}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "    except Exception as e:\n",
    "        print(e, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa1788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "374f0d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598ffcdc1a2a4845a79a6d45b9294777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_wordnet_pos(tagged_pos):\n",
    "    for pos in ['V', 'N', 'J', 'R']:\n",
    "        if tagged_pos.startswith(pos):\n",
    "            return pos.lower() if pos != 'J' else 'a'\n",
    "    return None\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "word_txt={}\n",
    "\n",
    "for txt_file in tqdm(glob('./Downloads/pdf_download/txt/*.txt')):\n",
    "    with open(txt_file, encoding='utf-8') as f:\n",
    "        txt = f.read().lower().replace('-\\n', '')\n",
    "        \n",
    "        \n",
    "    # 토크나이저\n",
    "        re_tokenizer = RegexpTokenizer('[a-zA-Z]{2,}')\n",
    "\n",
    "        # 토큰화\n",
    "        word_tokens = re_tokenizer.tokenize(txt)\n",
    "\n",
    "        # 불용어(stopwords) 제거\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words.append('cid')\n",
    "        word_tokens = [w for w in word_tokens if w not in stop_words]\n",
    "\n",
    "        #stemmer = PorterStemmer()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        word_tokens = [stemmer.stem(w) for w in word_tokens]\n",
    "\n",
    "        word_tokens = pos_tag(word_tokens)\n",
    "        word_tokens = [(w, get_wordnet_pos(tag)) for w, tag in word_tokens if get_wordnet_pos(tag) != None]\n",
    "        word_tokens = [lemm.lemmatize(word, pos=tag) for word, tag in word_tokens]\n",
    "        \n",
    "        if word_txt.values() == None:\n",
    "            for f in FreqDist(word_tokens):\n",
    "                word_txt[f]=txt_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2102dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keywords=FreqDist(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43b8ff3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/1526751606.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#스니펫 안나오는것 -> 관련질문\n",
    "\n",
    "#{f}가 제일먼저 나오는 text, 관련질문 맨 위에 있는 거 가져오기 ->클릭해야 보임\n",
    "#관련 내용 부분\n",
    "\n",
    "test_word=pd.read_csv('keywords.csv')\n",
    "test_words=test_word['0']\n",
    "terminologies={}\n",
    "\n",
    "explains=[]\n",
    "explains_url=[]\n",
    "\n",
    "\n",
    "#for feq in FreqDist(word_tokens):\n",
    "for feq in test_words:\n",
    "\n",
    "    driver.get('https://www.google.com')\n",
    "    search_elem=driver.find_element(By.CLASS_NAME, 'gLFyf.gsfi')\n",
    "\n",
    "    # 검색\n",
    "    search_elem.clear()\n",
    "    search_elem.send_keys(f'what is {feq} of deep learning')\n",
    "    driver.find_element(By.CLASS_NAME, 'gNO89b').submit()\n",
    "\n",
    "    related_question_elem=driver.find_elements(By.CLASS_NAME, 'Wt5Tfe') #mlist\n",
    "    each_question_elem=driver.find_elements(By.CLASS_NAME, 'wQiwMc.ygGdYd.related-question-pair') #clist\n",
    "    href_elem=driver.find_elements(By.CLASS_NAME, 'yuRUbf > a')#hreflist \n",
    "    explain_question_elem=driver.find_elements(By.CLASS_NAME,'LGOjhe')\n",
    "    explain_href_elem=driver.find_elements(By.CLASS_NAME, 'yuRUbf > a')\n",
    "    each_question_elem2=driver.find_elements(By.CLASS_NAME, 'wQiwMc.ygGdYd.related-question-pair')\n",
    "    \n",
    "    explain_elem=driver.find_elements(By.CLASS_NAME, 'yp1CPe.wDYxhc.NFQFxe.viOShc.LKPcQc > div > div > div > div')        \n",
    "    explain_href_elem=driver.find_elements(By.CLASS_NAME, 'yp1CPe.wDYxhc.NFQFxe.viOShc.LKPcQc > div > div > div > div > div > div > a')\n",
    "\n",
    "    def click_questions():\n",
    "        \n",
    "        \"\"\" 관련 질문 클릭하는 함수        \n",
    "        click_number=클릭 횟수 (많이 클릭할 필요가 없어 제한)\"\"\"\n",
    "        \n",
    "        for click_number,questions in enumerate(each_question_elem):\n",
    "            if click_number < 1:\n",
    "                questions.click()\n",
    "\n",
    "    for rqe in related_question_elem:\n",
    "        if rqe.is_displayed:\n",
    "            click_questions()\n",
    "    \n",
    "    \n",
    "        for explain in explain_question_elem:\n",
    "            explains.append(explain.text)\n",
    "            for exp_url in explain_href_elem:\n",
    "                explains_url.append(exp_url.get_attribute('href'))\n",
    "                \n",
    "                if terminologies.get(feq)==None:\n",
    "                    terminologies[feq]=explain.text\n",
    "\n",
    "    for ex in explain_elem:\n",
    "        if ex.is_displayed():            \n",
    "            explains.append(ex.text)\n",
    "            for eh in explain_href_elem:\n",
    "                explains_url.append(eh.get_attribute('href'))\n",
    "                if terminologies.get(feq)==None:\n",
    "                    time.sleep(1)\n",
    "                    terminologies[feq]=e.text\n",
    "                \n",
    "                \n",
    "\n",
    "        time.sleep(2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74153b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "\n",
    "Ttranslated={}\n",
    "translate_result=[]\n",
    "\n",
    "explain_translation={}\n",
    "keywords_translation={}\n",
    "\n",
    "for i in terminologies.values():\n",
    "    translator=Translator()\n",
    "    result=translator.translate(i, src='en', dest='ko')\n",
    "    translate_result.append(result.text)\n",
    "    explain_translation[i]=result.text #원문-번역 dict\n",
    "    \n",
    "keywords_translation=dict(zip(keywords.keys(),translate_result)) #단어-해석 dict\n",
    "\n",
    "test_keywords_translation = defaultdict(list)\n",
    "\n",
    "for k, v in chain(keywords.items(), keywords_translation.items()): #dict에서 중복되는거 리스트로 겹치게\n",
    "    test_keywords_translation[k].append(v)\n",
    "\n",
    "\n",
    "df2=pd.DataFrame.from_dict(dict(test_keywords_translation), orient='index')\n",
    "df2\n",
    "\n",
    "df2=pd.DataFrame.from_dict(dict(enumerate(test_keywords_translation.items())), orient='index')\n",
    "df2\n",
    "\n",
    "df2.to_csv(\"keywords.csv\",header=True, index=True, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61441e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>의미/해석</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['procedur', '기본 딥 러닝 아키텍처는 입력 크기가 고정되어 있으며 이는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['architectur', 'ImageNet은 계층의 각 노드가 수백 수천 개의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['imagenet', '데이터 증강은 기존 데이터에서 새로운 데이터 포인트를 생성...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['augment', '딥 러닝에서 컴퓨터 모델은 이미지, 텍스트 또는 사운드에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['differ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['tabl']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['timm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['epoch']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['paramet']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>['top']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>['seed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>['accuraci']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>['result']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>['batch']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>['mixup']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>['comput']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>['vision']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    단어                                              의미/해석\n",
       "0    0  ['procedur', '기본 딥 러닝 아키텍처는 입력 크기가 고정되어 있으며 이는...\n",
       "1    1  ['architectur', 'ImageNet은 계층의 각 노드가 수백 수천 개의 ...\n",
       "2    2  ['imagenet', '데이터 증강은 기존 데이터에서 새로운 데이터 포인트를 생성...\n",
       "3    3  ['augment', '딥 러닝에서 컴퓨터 모델은 이미지, 텍스트 또는 사운드에서 ...\n",
       "4    4                                          ['model']\n",
       "5    5                                         ['differ']\n",
       "6    6                                           ['tabl']\n",
       "7    7                                           ['timm']\n",
       "8    8                                          ['epoch']\n",
       "9    9                                        ['paramet']\n",
       "10  10                                            ['top']\n",
       "11  11                                           ['seed']\n",
       "12  12                                       ['accuraci']\n",
       "13  13                                         ['result']\n",
       "14  14                                          ['batch']\n",
       "15  15                                          ['mixup']\n",
       "16  16                                         ['comput']\n",
       "17  17                                         ['vision']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keywords_all=pd.read_csv('keywords.csv', index = False)#header=None)\n",
    "# keywords_all.rename(columns={'Unnamed: 0':'인덱스(빈도수)','0':'단어', '1':'의미/해석'}, inplace=True )\n",
    "keywords_all=pd.read_csv('keywords.csv', index_col=0)\n",
    "keywords_all.rename(columns={'0':'단어', '1':'의미/해석'}, inplace=True )\n",
    "keywords_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933008d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91787980",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = pd.read_csv('theory.csv')\n",
    "find_title = []\n",
    "pdf_title = theory[['pdf','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661513c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d4fc4e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiple_values_one_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7136/28582084.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtitles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpdf_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pdf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwords_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiple_values_one_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_title\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'multiple_values_one_key' is not defined"
     ]
    }
   ],
   "source": [
    "titles = pdf_title[pdf_title['pdf'].str.contains(txt_file_name, na=True)]\n",
    "\n",
    "words_title=multiple_values_one_key(words_title,word,[titles['title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "beed981e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['https://arxiv.org/pdf/1512.03385v1.pdf',\\n       'https://arxiv.org/pdf/1409.1556v6.pdf',\\n       'https://arxiv.org/pdf/1704.04861v1.pdf',\\n       'https://arxiv.org/pdf/1608.06993v5.pdf',\\n       'https://arxiv.org/pdf/1911.11929v1.pdf',\\n       'https://arxiv.org/pdf/1801.04381v4.pdf',\\n       'https://arxiv.org/pdf/1610.02391v4.pdf',\\n       'https://arxiv.org/pdf/1905.11946v5.pdf',\\n       'https://arxiv.org/pdf/1512.00567v3.pdf',\\n       'https://arxiv.org/pdf/2010.11929v2.pdf',\\n       'https://arxiv.org/pdf/1503.02531v1.pdf',\\n       'https://arxiv.org/pdf/1908.08962v2.pdf',\\n       'https://arxiv.org/pdf/1910.01108v4.pdf',\\n       'https://arxiv.org/pdf/2006.04558v6.pdf',\\n       'https://arxiv.org/pdf/1710.11063v3.pdf',\\n       'https://arxiv.org/pdf/2004.09813v2.pdf',\\n       'https://arxiv.org/pdf/1606.07947v4.pdf',\\n       'https://arxiv.org/pdf/1612.03928v3.pdf',\\n       'https://arxiv.org/pdf/1909.10351v5.pdf',\\n       'https://arxiv.org/pdf/1905.09717v5.pdf',\\n       'https://arxiv.org/pdf/1703.03400v3.pdf',\\n       'https://arxiv.org/pdf/1703.05175v2.pdf',\\n       'https://arxiv.org/pdf/1606.04080v2.pdf',\\n       'https://arxiv.org/pdf/2103.00020v1.pdf',\\n       'https://arxiv.org/pdf/1803.02999v3.pdf',\\n       'https://arxiv.org/pdf/1903.03096v4.pdf',\\n       'https://arxiv.org/pdf/1711.06025v2.pdf',\\n       'https://arxiv.org/pdf/1810.09502v3.pdf',\\n       'https://arxiv.org/pdf/1904.03758v2.pdf',\\n       'https://arxiv.org/pdf/1911.04623v2.pdf',\\n       'https://arxiv.org/pdf/1812.04606v3.pdf',\\n       'https://arxiv.org/pdf/1906.02845v2.pdf',\\n       'https://arxiv.org/pdf/1912.12510v2.pdf',\\n       'https://arxiv.org/pdf/2102.08248v7.pdf',\\n       'https://arxiv.org/pdf/2003.02977v3.pdf',\\n       'https://arxiv.org/pdf/2012.01316v4.pdf',\\n       'https://arxiv.org/pdf/2106.09022v1.pdf',\\n       'https://arxiv.org/pdf/1909.11480v3.pdf',\\n       'https://arxiv.org/pdf/2002.11297v2.pdf',\\n       'https://arxiv.org/pdf/2006.04005v3.pdf',\\n       'https://arxiv.org/pdf/1805.09501v3.pdf',\\n       'https://arxiv.org/pdf/2012.12877v2.pdf',\\n       'https://arxiv.org/pdf/2105.03404v2.pdf',\\n       'https://arxiv.org/pdf/2010.01412v3.pdf',\\n       'https://arxiv.org/pdf/2103.00112v3.pdf',\\n       'https://arxiv.org/pdf/1811.06965v5.pdf',\\n       'https://arxiv.org/pdf/2110.00476v1.pdf',\\n       'https://arxiv.org/pdf/2004.01461v2.pdf',\\n       'https://arxiv.org/pdf/1505.04597v1.pdf',\\n       'https://arxiv.org/pdf/1703.06870v3.pdf',\\n       'https://arxiv.org/pdf/1906.07155v1.pdf',\\n       'https://arxiv.org/pdf/1612.00593v2.pdf',\\n       'https://arxiv.org/pdf/1904.01355v5.pdf',\\n       'https://arxiv.org/pdf/1511.00561v3.pdf',\\n       'https://arxiv.org/pdf/1802.02611v3.pdf',\\n       'https://arxiv.org/pdf/1706.05587v3.pdf',\\n       'https://arxiv.org/pdf/1505.03540v3.pdf',\\n       'https://arxiv.org/pdf/1709.00382v2.pdf',\\n       'https://arxiv.org/pdf/1802.10508v1.pdf',\\n       'https://arxiv.org/pdf/1904.00445v2.pdf',\\n       'https://arxiv.org/pdf/1810.11654v3.pdf',\\n       'https://arxiv.org/pdf/1901.04056v1.pdf',\\n       'https://arxiv.org/pdf/1702.05970v2.pdf',\\n       'https://arxiv.org/pdf/1802.02427v2.pdf',\\n       'https://arxiv.org/pdf/1805.08403v3.pdf',\\n       'https://arxiv.org/pdf/1906.03720v1.pdf',\\n       'https://arxiv.org/pdf/2004.08955v2.pdf',\\n       'https://arxiv.org/pdf/2005.12872v3.pdf',\\n       'https://arxiv.org/pdf/2003.10152v3.pdf',\\n       'https://arxiv.org/pdf/1901.02446v2.pdf',\\n       'https://arxiv.org/pdf/1803.06815v3.pdf',\\n       'https://arxiv.org/pdf/1911.06667v6.pdf',\\n       'https://arxiv.org/pdf/2005.10821v1.pdf',\\n       'https://arxiv.org/pdf/2106.13797v5.pdf',\\n       'https://arxiv.org/pdf/1911.10194v3.pdf',\\n       'https://arxiv.org/pdf/1706.02413v1.pdf',\\n       'https://arxiv.org/pdf/1710.07368v1.pdf',\\n       'https://arxiv.org/pdf/1904.08889v2.pdf',\\n       'https://arxiv.org/pdf/1711.10275v1.pdf',\\n       'https://arxiv.org/pdf/1812.02713v1.pdf',\\n       'https://arxiv.org/pdf/1904.08755v4.pdf',\\n       'https://arxiv.org/pdf/1911.11236v3.pdf',\\n       'https://arxiv.org/pdf/2003.03653v3.pdf',\\n       'https://arxiv.org/pdf/2007.10732v1.pdf',\\n       'https://arxiv.org/pdf/1805.04628v2.pdf',\\n       'https://arxiv.org/pdf/1904.05044v3.pdf',\\n       'https://arxiv.org/pdf/1502.02734v3.pdf',\\n       'https://arxiv.org/pdf/2101.11253v4.pdf',\\n       'https://arxiv.org/pdf/1412.7144v4.pdf',\\n       'https://arxiv.org/pdf/1803.10464v2.pdf',\\n       'http://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Integral_Object_Mining_via_Online_Attention_Accumulation_ICCV_2019_paper.pdf',\\n       'http://openaccess.thecvf.com/content_ICCV_2019/papers/Chan_HistoSegNet_Semantic_Segmentation_of_Histological_Tissue_Type_in_Whole_Slide_ICCV_2019_paper.pdf',\\n       'https://arxiv.org/pdf/2004.04581v1.pdf',\\n       'https://arxiv.org/pdf/2007.01947v2.pdf'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16140/3035281581.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtitles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpdf_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pdf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpdf_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['https://arxiv.org/pdf/1512.03385v1.pdf',\\n       'https://arxiv.org/pdf/1409.1556v6.pdf',\\n       'https://arxiv.org/pdf/1704.04861v1.pdf',\\n       'https://arxiv.org/pdf/1608.06993v5.pdf',\\n       'https://arxiv.org/pdf/1911.11929v1.pdf',\\n       'https://arxiv.org/pdf/1801.04381v4.pdf',\\n       'https://arxiv.org/pdf/1610.02391v4.pdf',\\n       'https://arxiv.org/pdf/1905.11946v5.pdf',\\n       'https://arxiv.org/pdf/1512.00567v3.pdf',\\n       'https://arxiv.org/pdf/2010.11929v2.pdf',\\n       'https://arxiv.org/pdf/1503.02531v1.pdf',\\n       'https://arxiv.org/pdf/1908.08962v2.pdf',\\n       'https://arxiv.org/pdf/1910.01108v4.pdf',\\n       'https://arxiv.org/pdf/2006.04558v6.pdf',\\n       'https://arxiv.org/pdf/1710.11063v3.pdf',\\n       'https://arxiv.org/pdf/2004.09813v2.pdf',\\n       'https://arxiv.org/pdf/1606.07947v4.pdf',\\n       'https://arxiv.org/pdf/1612.03928v3.pdf',\\n       'https://arxiv.org/pdf/1909.10351v5.pdf',\\n       'https://arxiv.org/pdf/1905.09717v5.pdf',\\n       'https://arxiv.org/pdf/1703.03400v3.pdf',\\n       'https://arxiv.org/pdf/1703.05175v2.pdf',\\n       'https://arxiv.org/pdf/1606.04080v2.pdf',\\n       'https://arxiv.org/pdf/2103.00020v1.pdf',\\n       'https://arxiv.org/pdf/1803.02999v3.pdf',\\n       'https://arxiv.org/pdf/1903.03096v4.pdf',\\n       'https://arxiv.org/pdf/1711.06025v2.pdf',\\n       'https://arxiv.org/pdf/1810.09502v3.pdf',\\n       'https://arxiv.org/pdf/1904.03758v2.pdf',\\n       'https://arxiv.org/pdf/1911.04623v2.pdf',\\n       'https://arxiv.org/pdf/1812.04606v3.pdf',\\n       'https://arxiv.org/pdf/1906.02845v2.pdf',\\n       'https://arxiv.org/pdf/1912.12510v2.pdf',\\n       'https://arxiv.org/pdf/2102.08248v7.pdf',\\n       'https://arxiv.org/pdf/2003.02977v3.pdf',\\n       'https://arxiv.org/pdf/2012.01316v4.pdf',\\n       'https://arxiv.org/pdf/2106.09022v1.pdf',\\n       'https://arxiv.org/pdf/1909.11480v3.pdf',\\n       'https://arxiv.org/pdf/2002.11297v2.pdf',\\n       'https://arxiv.org/pdf/2006.04005v3.pdf',\\n       'https://arxiv.org/pdf/1805.09501v3.pdf',\\n       'https://arxiv.org/pdf/2012.12877v2.pdf',\\n       'https://arxiv.org/pdf/2105.03404v2.pdf',\\n       'https://arxiv.org/pdf/2010.01412v3.pdf',\\n       'https://arxiv.org/pdf/2103.00112v3.pdf',\\n       'https://arxiv.org/pdf/1811.06965v5.pdf',\\n       'https://arxiv.org/pdf/2110.00476v1.pdf',\\n       'https://arxiv.org/pdf/2004.01461v2.pdf',\\n       'https://arxiv.org/pdf/1505.04597v1.pdf',\\n       'https://arxiv.org/pdf/1703.06870v3.pdf',\\n       'https://arxiv.org/pdf/1906.07155v1.pdf',\\n       'https://arxiv.org/pdf/1612.00593v2.pdf',\\n       'https://arxiv.org/pdf/1904.01355v5.pdf',\\n       'https://arxiv.org/pdf/1511.00561v3.pdf',\\n       'https://arxiv.org/pdf/1802.02611v3.pdf',\\n       'https://arxiv.org/pdf/1706.05587v3.pdf',\\n       'https://arxiv.org/pdf/1505.03540v3.pdf',\\n       'https://arxiv.org/pdf/1709.00382v2.pdf',\\n       'https://arxiv.org/pdf/1802.10508v1.pdf',\\n       'https://arxiv.org/pdf/1904.00445v2.pdf',\\n       'https://arxiv.org/pdf/1810.11654v3.pdf',\\n       'https://arxiv.org/pdf/1901.04056v1.pdf',\\n       'https://arxiv.org/pdf/1702.05970v2.pdf',\\n       'https://arxiv.org/pdf/1802.02427v2.pdf',\\n       'https://arxiv.org/pdf/1805.08403v3.pdf',\\n       'https://arxiv.org/pdf/1906.03720v1.pdf',\\n       'https://arxiv.org/pdf/2004.08955v2.pdf',\\n       'https://arxiv.org/pdf/2005.12872v3.pdf',\\n       'https://arxiv.org/pdf/2003.10152v3.pdf',\\n       'https://arxiv.org/pdf/1901.02446v2.pdf',\\n       'https://arxiv.org/pdf/1803.06815v3.pdf',\\n       'https://arxiv.org/pdf/1911.06667v6.pdf',\\n       'https://arxiv.org/pdf/2005.10821v1.pdf',\\n       'https://arxiv.org/pdf/2106.13797v5.pdf',\\n       'https://arxiv.org/pdf/1911.10194v3.pdf',\\n       'https://arxiv.org/pdf/1706.02413v1.pdf',\\n       'https://arxiv.org/pdf/1710.07368v1.pdf',\\n       'https://arxiv.org/pdf/1904.08889v2.pdf',\\n       'https://arxiv.org/pdf/1711.10275v1.pdf',\\n       'https://arxiv.org/pdf/1812.02713v1.pdf',\\n       'https://arxiv.org/pdf/1904.08755v4.pdf',\\n       'https://arxiv.org/pdf/1911.11236v3.pdf',\\n       'https://arxiv.org/pdf/2003.03653v3.pdf',\\n       'https://arxiv.org/pdf/2007.10732v1.pdf',\\n       'https://arxiv.org/pdf/1805.04628v2.pdf',\\n       'https://arxiv.org/pdf/1904.05044v3.pdf',\\n       'https://arxiv.org/pdf/1502.02734v3.pdf',\\n       'https://arxiv.org/pdf/2101.11253v4.pdf',\\n       'https://arxiv.org/pdf/1412.7144v4.pdf',\\n       'https://arxiv.org/pdf/1803.10464v2.pdf',\\n       'http://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Integral_Object_Mining_via_Online_Attention_Accumulation_ICCV_2019_paper.pdf',\\n       'http://openaccess.thecvf.com/content_ICCV_2019/papers/Chan_HistoSegNet_Semantic_Segmentation_of_Histological_Tissue_Type_in_Whole_Slide_ICCV_2019_paper.pdf',\\n       'https://arxiv.org/pdf/2004.04581v1.pdf',\\n       'https://arxiv.org/pdf/2007.01947v2.pdf'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "pdf_test={}\n",
    "pdf_title.to\n",
    "\n",
    "for txt_file in glob('./Downloads/pdf_download/txt/*.txt'):\n",
    "    txt_file_name = os.path.basename(txt_file).replace('.txt','')        \n",
    "    with open(txt_file, encoding='utf-8') as file:\n",
    "        #titles = pdf_title[pdf_title['pdf'].str.contains(txt_file_name, na=True)]['title']\n",
    "        #pdf_test[title]=pdf_title[pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "625b90ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       pdf  \\\n",
      "46  https://arxiv.org/pdf/2110.00476v1.pdf   \n",
      "\n",
      "                                                title  \n",
      "46  ResNet strikes back: An improved training proc...  \n"
     ]
    }
   ],
   "source": [
    "for txt_file in glob('./Downloads/pdf_download/txt/*.txt'):\n",
    "    txt_file_name = os.path.basename(txt_file).replace('.txt','')        \n",
    "    with open(txt_file, encoding='utf-8') as file:\n",
    "        titles = pdf_title[pdf_title['pdf'].str.contains(txt_file_name, na=True)]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130d7729",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2352/963035998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpdf_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msecond_classification\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'second_classification.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwords_titles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word-titles.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pdf_title' is not defined"
     ]
    }
   ],
   "source": [
    "pdf_title.to_dict('records')\n",
    "\n",
    "second_classification=pd.read_csv('second_classification.csv')\n",
    "words_titles=pd.read_csv('word-titles.csv')\n",
    "\n",
    "\n",
    "#cla1_cla2_title=pd.merge(left=second_classification,right=classification_without_word, how='left',on=)\n",
    "\n",
    "\n",
    "for number in range(len(first_classification.columns)-1):\n",
    "    for cla2 in second_classification['0']:\n",
    "        cla1=classification_without_word[f'{number}'].str.contains(f'{cla2}')\n",
    "        cla_cla2_title[cla2]=cla1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885f419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computer vision</th>\n",
       "      <th>methodology</th>\n",
       "      <th>music</th>\n",
       "      <th>adversarial</th>\n",
       "      <th>natural language processing</th>\n",
       "      <th>playing games</th>\n",
       "      <th>medical</th>\n",
       "      <th>graphs</th>\n",
       "      <th>robots</th>\n",
       "      <th>speech</th>\n",
       "      <th>time series</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>miscellaneous</th>\n",
       "      <th>audio</th>\n",
       "      <th>computer code</th>\n",
       "      <th>knowledge base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Knowledge Distillation</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>Image-to-Image Translation</td>\n",
       "      <td>Text Augmentation</td>\n",
       "      <td>Object Tracking</td>\n",
       "      <td>Knee Cartilage Defect Assessment</td>\n",
       "      <td>Knowledge Graph Embedding</td>\n",
       "      <td>3D Face Reconstruction</td>\n",
       "      <td>Speech Emotion Recognition</td>\n",
       "      <td>Trajectory Prediction</td>\n",
       "      <td>Visual Reasoning</td>\n",
       "      <td>Remote Sensing Image Classification</td>\n",
       "      <td>Synthetic Speech Detection</td>\n",
       "      <td>motion style transfer</td>\n",
       "      <td>Breast Cancer Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OOD Detection</td>\n",
       "      <td>Few-Shot Image Classification</td>\n",
       "      <td>Music Texture Transfer</td>\n",
       "      <td>Adversarial Attack</td>\n",
       "      <td>Machine Reading Comprehension</td>\n",
       "      <td>Continuous Control</td>\n",
       "      <td>Medical Image Segmentation</td>\n",
       "      <td>3D Hand Pose Estimation</td>\n",
       "      <td>Drone Controller</td>\n",
       "      <td>Keyword Spotting</td>\n",
       "      <td>Human motion prediction</td>\n",
       "      <td>Visual Commonsense Reasoning</td>\n",
       "      <td>Change detection for remote sensing images</td>\n",
       "      <td>Audio Fingerprint</td>\n",
       "      <td>Code Search</td>\n",
       "      <td>Entity Alignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fine-Grained Image Classification</td>\n",
       "      <td>Domain Adaptation</td>\n",
       "      <td>Music Information Retrieval</td>\n",
       "      <td>Real-World Adversarial Attack</td>\n",
       "      <td>Emotion Recognition in Conversation</td>\n",
       "      <td>Car Racing</td>\n",
       "      <td>Lesion Segmentation</td>\n",
       "      <td>Graph Embedding</td>\n",
       "      <td>Visual Odometry</td>\n",
       "      <td>Small-Footprint Keyword Spotting</td>\n",
       "      <td>Imputation</td>\n",
       "      <td>Visual Entailment</td>\n",
       "      <td>Segmentation Of Remote Sensing Imagery</td>\n",
       "      <td>Audio-Visual Synchronization</td>\n",
       "      <td>Code Generation</td>\n",
       "      <td>research knowledge graph population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic Segmentation</td>\n",
       "      <td>Unsupervised Domain Adaptation</td>\n",
       "      <td>Music Source Separation</td>\n",
       "      <td>Model Posioning</td>\n",
       "      <td>Emotion-Cause Pair Extraction</td>\n",
       "      <td>SMAC</td>\n",
       "      <td>Brain Tumor Segmentation</td>\n",
       "      <td>Learning-To-Rank</td>\n",
       "      <td>Monocular Visual Odometry</td>\n",
       "      <td>Talking Face Generation</td>\n",
       "      <td>Multivariate Time Series Imputation</td>\n",
       "      <td>Abstract Argumentation</td>\n",
       "      <td>Lake Ice Monitoring</td>\n",
       "      <td>Language Identification</td>\n",
       "      <td>Source Code Summarization</td>\n",
       "      <td>Non-Intrusive Load Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tumor Segmentation</td>\n",
       "      <td>Domain Generalization</td>\n",
       "      <td>Music Transcription</td>\n",
       "      <td>Website Fingerprinting Defense</td>\n",
       "      <td>Image Captioning</td>\n",
       "      <td>DQN Replay Dataset</td>\n",
       "      <td>Brain Segmentation</td>\n",
       "      <td>NMR J-coupling</td>\n",
       "      <td>3D Character Animation From A Single Photo</td>\n",
       "      <td>Speech Recognition</td>\n",
       "      <td>Sequential skip prediction</td>\n",
       "      <td>Commonsense Reasoning for RL</td>\n",
       "      <td>The Semantic Segmentation Of Remote Sensing Im...</td>\n",
       "      <td>Zero-Shot Multi-Speaker TTS</td>\n",
       "      <td>Neural Network simulation</td>\n",
       "      <td>Link Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>6D Pose Estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>6D Pose Estimation using RGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Head Pose Estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Vehicle Pose Estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>6D Pose Estimation using RGBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       computer vision                     methodology  \\\n",
       "0                 Image Classification          Knowledge Distillation   \n",
       "1                        OOD Detection   Few-Shot Image Classification   \n",
       "2    Fine-Grained Image Classification               Domain Adaptation   \n",
       "3                Semantic Segmentation  Unsupervised Domain Adaptation   \n",
       "4                   Tumor Segmentation           Domain Generalization   \n",
       "..                                 ...                             ...   \n",
       "777                 6D Pose Estimation                             NaN   \n",
       "778       6D Pose Estimation using RGB                             NaN   \n",
       "779               Head Pose Estimation                             NaN   \n",
       "780            Vehicle Pose Estimation                             NaN   \n",
       "781      6D Pose Estimation using RGBD                             NaN   \n",
       "\n",
       "                           music                     adversarial  \\\n",
       "0               Image Generation      Image-to-Image Translation   \n",
       "1         Music Texture Transfer              Adversarial Attack   \n",
       "2    Music Information Retrieval   Real-World Adversarial Attack   \n",
       "3        Music Source Separation                 Model Posioning   \n",
       "4            Music Transcription  Website Fingerprinting Defense   \n",
       "..                           ...                             ...   \n",
       "777                          NaN                             NaN   \n",
       "778                          NaN                             NaN   \n",
       "779                          NaN                             NaN   \n",
       "780                          NaN                             NaN   \n",
       "781                          NaN                             NaN   \n",
       "\n",
       "             natural language processing       playing games  \\\n",
       "0                      Text Augmentation     Object Tracking   \n",
       "1          Machine Reading Comprehension  Continuous Control   \n",
       "2    Emotion Recognition in Conversation          Car Racing   \n",
       "3          Emotion-Cause Pair Extraction                SMAC   \n",
       "4                       Image Captioning  DQN Replay Dataset   \n",
       "..                                   ...                 ...   \n",
       "777                                  NaN                 NaN   \n",
       "778                                  NaN                 NaN   \n",
       "779                                  NaN                 NaN   \n",
       "780                                  NaN                 NaN   \n",
       "781                                  NaN                 NaN   \n",
       "\n",
       "                              medical                     graphs  \\\n",
       "0    Knee Cartilage Defect Assessment  Knowledge Graph Embedding   \n",
       "1          Medical Image Segmentation    3D Hand Pose Estimation   \n",
       "2                 Lesion Segmentation            Graph Embedding   \n",
       "3            Brain Tumor Segmentation           Learning-To-Rank   \n",
       "4                  Brain Segmentation             NMR J-coupling   \n",
       "..                                ...                        ...   \n",
       "777                               NaN                        NaN   \n",
       "778                               NaN                        NaN   \n",
       "779                               NaN                        NaN   \n",
       "780                               NaN                        NaN   \n",
       "781                               NaN                        NaN   \n",
       "\n",
       "                                         robots  \\\n",
       "0                        3D Face Reconstruction   \n",
       "1                              Drone Controller   \n",
       "2                               Visual Odometry   \n",
       "3                     Monocular Visual Odometry   \n",
       "4    3D Character Animation From A Single Photo   \n",
       "..                                          ...   \n",
       "777                                         NaN   \n",
       "778                                         NaN   \n",
       "779                                         NaN   \n",
       "780                                         NaN   \n",
       "781                                         NaN   \n",
       "\n",
       "                               speech                          time series  \\\n",
       "0          Speech Emotion Recognition                Trajectory Prediction   \n",
       "1                    Keyword Spotting              Human motion prediction   \n",
       "2    Small-Footprint Keyword Spotting                           Imputation   \n",
       "3             Talking Face Generation  Multivariate Time Series Imputation   \n",
       "4                  Speech Recognition           Sequential skip prediction   \n",
       "..                                ...                                  ...   \n",
       "777                               NaN                                  NaN   \n",
       "778                               NaN                                  NaN   \n",
       "779                               NaN                                  NaN   \n",
       "780                               NaN                                  NaN   \n",
       "781                               NaN                                  NaN   \n",
       "\n",
       "                        reasoning  \\\n",
       "0                Visual Reasoning   \n",
       "1    Visual Commonsense Reasoning   \n",
       "2               Visual Entailment   \n",
       "3          Abstract Argumentation   \n",
       "4    Commonsense Reasoning for RL   \n",
       "..                            ...   \n",
       "777                           NaN   \n",
       "778                           NaN   \n",
       "779                           NaN   \n",
       "780                           NaN   \n",
       "781                           NaN   \n",
       "\n",
       "                                         miscellaneous  \\\n",
       "0                  Remote Sensing Image Classification   \n",
       "1           Change detection for remote sensing images   \n",
       "2               Segmentation Of Remote Sensing Imagery   \n",
       "3                                  Lake Ice Monitoring   \n",
       "4    The Semantic Segmentation Of Remote Sensing Im...   \n",
       "..                                                 ...   \n",
       "777                                                NaN   \n",
       "778                                                NaN   \n",
       "779                                                NaN   \n",
       "780                                                NaN   \n",
       "781                                                NaN   \n",
       "\n",
       "                            audio              computer code  \\\n",
       "0      Synthetic Speech Detection      motion style transfer   \n",
       "1               Audio Fingerprint                Code Search   \n",
       "2    Audio-Visual Synchronization            Code Generation   \n",
       "3         Language Identification  Source Code Summarization   \n",
       "4     Zero-Shot Multi-Speaker TTS  Neural Network simulation   \n",
       "..                            ...                        ...   \n",
       "777                           NaN                        NaN   \n",
       "778                           NaN                        NaN   \n",
       "779                           NaN                        NaN   \n",
       "780                           NaN                        NaN   \n",
       "781                           NaN                        NaN   \n",
       "\n",
       "                          knowledge base  \n",
       "0                Breast Cancer Detection  \n",
       "1                       Entity Alignment  \n",
       "2    research knowledge graph population  \n",
       "3          Non-Intrusive Load Monitoring  \n",
       "4                        Link Prediction  \n",
       "..                                   ...  \n",
       "777                                  NaN  \n",
       "778                                  NaN  \n",
       "779                                  NaN  \n",
       "780                                  NaN  \n",
       "781                                  NaN  \n",
       "\n",
       "[782 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_classification_all=pd.read_csv('first_classification-Copy1.csv').T\n",
    "\n",
    "columns = first_classification_all.iloc[0].values\n",
    "first_classification_all.columns = columns\n",
    "\n",
    "first_classification_all = first_classification_all.iloc[1:]\n",
    "first_classification_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd7e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_classification = pd.read_csv('second_classification-Copy1.csv', index_col=0)\n",
    "second_classification.drop(columns=['Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a045c583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cla2</th>\n",
       "      <th>cla1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>Retinal OCT Disease Classification</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Deep Convolutional Networks for Large-Sca...</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MobileNets: Efficient Convolutional Neural Net...</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Densely Connected Convolutional Networks</td>\n",
       "      <td>Crowd Counting</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSPNet: A New Backbone that can Enhance Learni...</td>\n",
       "      <td>Real-Time Object Detection</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Dynamic Distillation Network for Cross-Domain ...</td>\n",
       "      <td>cross-domain few-shot learning</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>DeepMatching: Hierarchical Deformable Dense Ma...</td>\n",
       "      <td>Dense Pixel Correspondence Estimation</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>DGC-Net: Dense Geometric Correspondence Network</td>\n",
       "      <td>Dense Pixel Correspondence Estimation</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>Space-Time Correspondence as a Contrastive Ran...</td>\n",
       "      <td>Dense Pixel Correspondence Estimation</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>COTR: Correspondence Transformer for Matching ...</td>\n",
       "      <td>Dense Pixel Correspondence Estimation</td>\n",
       "      <td>computer vision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3255 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0          Deep Residual Learning for Image Recognition   \n",
       "1     Very Deep Convolutional Networks for Large-Sca...   \n",
       "2     MobileNets: Efficient Convolutional Neural Net...   \n",
       "3              Densely Connected Convolutional Networks   \n",
       "4     CSPNet: A New Backbone that can Enhance Learni...   \n",
       "...                                                 ...   \n",
       "3250  Dynamic Distillation Network for Cross-Domain ...   \n",
       "3251  DeepMatching: Hierarchical Deformable Dense Ma...   \n",
       "3252    DGC-Net: Dense Geometric Correspondence Network   \n",
       "3253  Space-Time Correspondence as a Contrastive Ran...   \n",
       "3254  COTR: Correspondence Transformer for Matching ...   \n",
       "\n",
       "                                       cla2             cla1  \n",
       "0        Retinal OCT Disease Classification  computer vision  \n",
       "1                      Image Classification  computer vision  \n",
       "2                      Image Classification  computer vision  \n",
       "3                            Crowd Counting  computer vision  \n",
       "4                Real-Time Object Detection  computer vision  \n",
       "...                                     ...              ...  \n",
       "3250         cross-domain few-shot learning  computer vision  \n",
       "3251  Dense Pixel Correspondence Estimation  computer vision  \n",
       "3252  Dense Pixel Correspondence Estimation  computer vision  \n",
       "3253  Dense Pixel Correspondence Estimation  computer vision  \n",
       "3254  Dense Pixel Correspondence Estimation  computer vision  \n",
       "\n",
       "[3255 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cla1 = []\n",
    "for second in second_classification.cla2.values:\n",
    "    for first in first_classification_all.columns:\n",
    "        status = 0\n",
    "        if second in first_classification_all[first].values:\n",
    "            cla1.append(first)\n",
    "            status = 1\n",
    "            break\n",
    "    if not status:\n",
    "        cla1.append(np.nan)\n",
    "\n",
    "second_classification['cla1'] = cla1\n",
    "second_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "487b4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cla1_list=[]\n",
    "cla2_list=[]\n",
    "\n",
    "for title in pdf_title['title'].values:\n",
    "    #for class2 \n",
    "    if title in second_classification.title.values:\n",
    "        find_cla2 = second_classification[second_classification['title'] == title]\n",
    "        for cla2s in find_cla2.values:\n",
    "            for cla2 in cla2s[1::3]:\n",
    "                cla2_list.append(cla2)\n",
    "            for cla1 in cla2s[2::3]:\n",
    "                cla1_list.append(cla1)\n",
    "                \n",
    "pdf_title['cla1'] = cla1_list\n",
    "pdf_title['cla2'] = cla2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d7a8ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_title.to_csv('pdf_title_cla1_cla2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c35f1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf</th>\n",
       "      <th>title</th>\n",
       "      <th>cla1</th>\n",
       "      <th>cla2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://arxiv.org/pdf/1512.03385v1.pdf</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Retinal OCT Disease Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://arxiv.org/pdf/1409.1556v6.pdf</td>\n",
       "      <td>Very Deep Convolutional Networks for Large-Sca...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Image Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://arxiv.org/pdf/1704.04861v1.pdf</td>\n",
       "      <td>MobileNets: Efficient Convolutional Neural Net...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Image Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://arxiv.org/pdf/1608.06993v5.pdf</td>\n",
       "      <td>Densely Connected Convolutional Networks</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Crowd Counting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://arxiv.org/pdf/1911.11929v1.pdf</td>\n",
       "      <td>CSPNet: A New Backbone that can Enhance Learni...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Real-Time Object Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>https://arxiv.org/pdf/1803.10464v2.pdf</td>\n",
       "      <td>Learning Pixel-level Semantic Affinity with Im...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Weakly-Supervised Semantic Segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "      <td>Integral Object Mining via Online Attention Ac...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Weakly supervised segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>http://openaccess.thecvf.com/content_ICCV_2019...</td>\n",
       "      <td>HistoSegNet: Semantic Segmentation of Histolog...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>whole slide images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>https://arxiv.org/pdf/2004.04581v1.pdf</td>\n",
       "      <td>Self-supervised Equivariant Attention Mechanis...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Weakly-Supervised Semantic Segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>https://arxiv.org/pdf/2007.01947v2.pdf</td>\n",
       "      <td>Mining Cross-Image Semantics for Weakly Superv...</td>\n",
       "      <td>computer vision</td>\n",
       "      <td>Weakly-Supervised Semantic Segmentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pdf  \\\n",
       "0              https://arxiv.org/pdf/1512.03385v1.pdf   \n",
       "1               https://arxiv.org/pdf/1409.1556v6.pdf   \n",
       "2              https://arxiv.org/pdf/1704.04861v1.pdf   \n",
       "3              https://arxiv.org/pdf/1608.06993v5.pdf   \n",
       "4              https://arxiv.org/pdf/1911.11929v1.pdf   \n",
       "..                                                ...   \n",
       "89             https://arxiv.org/pdf/1803.10464v2.pdf   \n",
       "90  http://openaccess.thecvf.com/content_ICCV_2019...   \n",
       "91  http://openaccess.thecvf.com/content_ICCV_2019...   \n",
       "92             https://arxiv.org/pdf/2004.04581v1.pdf   \n",
       "93             https://arxiv.org/pdf/2007.01947v2.pdf   \n",
       "\n",
       "                                                title             cla1  \\\n",
       "0        Deep Residual Learning for Image Recognition  computer vision   \n",
       "1   Very Deep Convolutional Networks for Large-Sca...  computer vision   \n",
       "2   MobileNets: Efficient Convolutional Neural Net...  computer vision   \n",
       "3            Densely Connected Convolutional Networks  computer vision   \n",
       "4   CSPNet: A New Backbone that can Enhance Learni...  computer vision   \n",
       "..                                                ...              ...   \n",
       "89  Learning Pixel-level Semantic Affinity with Im...  computer vision   \n",
       "90  Integral Object Mining via Online Attention Ac...  computer vision   \n",
       "91  HistoSegNet: Semantic Segmentation of Histolog...  computer vision   \n",
       "92  Self-supervised Equivariant Attention Mechanis...  computer vision   \n",
       "93  Mining Cross-Image Semantics for Weakly Superv...  computer vision   \n",
       "\n",
       "                                       cla2  \n",
       "0        Retinal OCT Disease Classification  \n",
       "1                      Image Classification  \n",
       "2                      Image Classification  \n",
       "3                            Crowd Counting  \n",
       "4                Real-Time Object Detection  \n",
       "..                                      ...  \n",
       "89  Weakly-Supervised Semantic Segmentation  \n",
       "90           Weakly supervised segmentation  \n",
       "91                       whole slide images  \n",
       "92  Weakly-Supervised Semantic Segmentation  \n",
       "93  Weakly-Supervised Semantic Segmentation  \n",
       "\n",
       "[94 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_title_cla1_cla2=pd.read_csv('pdf_title_cla1_cla2.csv', index_col=0)\n",
    "pdf_title_cla1_cla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bd330196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Residual Learning for Image Recognition\n",
      "Retinal OCT Disease Classification\n",
      "computer vision\n",
      "Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
      "Image Classification\n",
      "computer vision\n",
      "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n",
      "Image Classification\n",
      "computer vision\n",
      "Densely Connected Convolutional Networks\n",
      "Crowd Counting\n",
      "computer vision\n",
      "CSPNet: A New Backbone that can Enhance Learning Capability of CNN\n",
      "Real-Time Object Detection\n",
      "computer vision\n",
      "MobileNetV2: Inverted Residuals and Linear Bottlenecks\n",
      "Retinal OCT Disease Classification\n",
      "computer vision\n",
      "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\n",
      "Visual Question Answering\n",
      "computer vision\n",
      "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "Rethinking the Inception Architecture for Computer Vision\n",
      "Retinal OCT Disease Classification\n",
      "computer vision\n",
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "Distilling the Knowledge in a Neural Network\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Well-Read Students Learn Better: On the Importance of Pre-training Compact Models\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks\n",
      "Object Localization\n",
      "computer vision\n",
      "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Sequence-Level Knowledge Distillation\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "TinyBERT: Distilling BERT for Natural Language Understanding\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Network Pruning via Transformable Architecture Search\n",
      "Knowledge Distillation\n",
      "methodology\n",
      "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n",
      "One-Shot Learning\n",
      "methodology\n",
      "Prototypical Networks for Few-shot Learning\n",
      "Zero-Shot Learning\n",
      "methodology\n",
      "Matching Networks for One Shot Learning\n",
      "Metric Learning\n",
      "methodology\n",
      "Learning Transferable Visual Models From Natural Language Supervision\n",
      "Few-Shot Image Classification\n",
      "methodology\n",
      "On First-Order Meta-Learning Algorithms\n",
      "Few-Shot Learning\n",
      "methodology\n",
      "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples\n",
      "Meta-Learning\n",
      "methodology\n",
      "Learning to Compare: Relation Network for Few-Shot Learning\n",
      "Zero-Shot Learning\n",
      "methodology\n",
      "How to train your MAML\n",
      "Few-Shot Learning\n",
      "methodology\n",
      "Meta-Learning with Differentiable Convex Optimization\n",
      "Few-Shot Learning\n",
      "methodology\n",
      "SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning\n",
      "Few-Shot Image Classification\n",
      "methodology\n",
      "Deep Anomaly Detection with Outlier Exposure\n",
      "Out-of-Distribution Detection\n",
      "computer vision\n",
      "Likelihood Ratios for Out-of-Distribution Detection\n",
      "Out-of-Distribution Detection\n",
      "computer vision\n",
      "Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices\n",
      "Out-of-Distribution Detection\n",
      "computer vision\n",
      "Hierarchical VAEs Know What They Don't Know\n",
      "Out-of-Distribution Detection\n",
      "computer vision\n",
      "Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder\n",
      "OOD Detection\n",
      "computer vision\n",
      "Improved Contrastive Divergence Training of Energy Based Models\n",
      "OOD Detection\n",
      "computer vision\n",
      "A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection\n",
      "OOD Detection\n",
      "computer vision\n",
      "Input complexity and out-of-distribution detection with likelihood-based generative models\n",
      "OOD Detection\n",
      "computer vision\n",
      "Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data\n",
      "OOD Detection\n",
      "computer vision\n",
      "Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples\n",
      "OOD Detection\n",
      "computer vision\n",
      "AutoAugment: Learning Augmentation Policies from Data\n",
      "Image Augmentation\n",
      "computer vision\n",
      "Training data-efficient image transformers & distillation through attention\n",
      "Document Layout Analysis\n",
      "computer vision\n",
      "ResMLP: Feedforward networks for image classification with data-efficient training\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "Sharpness-Aware Minimization for Efficiently Improving Generalization\n",
      "Learning with noisy labels\n",
      "natural language processing\n",
      "Transformer in Transformer\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "ResNet strikes back: An improved training procedure in timm\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "Gradient Centralization: A New Optimization Technique for Deep Neural Networks\n",
      "Fine-Grained Image Classification\n",
      "computer vision\n",
      "U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
      "Thermal Image Segmentation\n",
      "computer vision\n",
      "Mask R-CNN\n",
      "Multi-Human Parsing\n",
      "computer vision\n",
      "MMDetection: Open MMLab Detection Toolbox and Benchmark\n",
      "Instance Segmentation\n",
      "computer vision\n",
      "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\n",
      "3D Point Cloud Classification\n",
      "computer vision\n",
      "FCOS: Fully Convolutional One-Stage Object Detection\n",
      "Semantic Segmentation\n",
      "computer vision\n",
      "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n",
      "Thermal Image Segmentation\n",
      "computer vision\n",
      "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\n",
      "Lesion Segmentation\n",
      "medical\n",
      "Rethinking Atrous Convolution for Semantic Image Segmentation\n",
      "Thermal Image Segmentation\n",
      "computer vision\n",
      "Brain Tumor Segmentation with Deep Neural Networks\n",
      "Brain Tumor Segmentation\n",
      "medical\n",
      "Automatic Brain Tumor Segmentation using Cascaded Anisotropic Convolutional Neural Networks\n",
      "Brain Tumor Segmentation\n",
      "medical\n",
      "Brain Tumor Segmentation and Radiomics Survival Prediction: Contribution to the BRATS 2017 Challenge\n",
      "Brain Tumor Segmentation\n",
      "medical\n",
      "The KiTS19 Challenge Data: 300 Kidney Tumor Cases with Clinical Context, CT Semantic Segmentations, and Surgical Outcomes\n",
      "Tumor Segmentation\n",
      "computer vision\n",
      "3D MRI brain tumor segmentation using autoencoder regularization\n",
      "Brain Tumor Segmentation\n",
      "medical\n",
      "The Liver Tumor Segmentation Benchmark (LiTS)\n",
      "Tumor Segmentation\n",
      "computer vision\n",
      "Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks\n",
      "Lesion Segmentation\n",
      "medical\n",
      "MRI Tumor Segmentation with Densely Connected 3D CNN\n",
      "Tumor Segmentation\n",
      "computer vision\n",
      "Autofocus Layer for Semantic Segmentation\n",
      "Brain Tumor Segmentation\n",
      "medical\n",
      "Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm\n",
      "Brain Segmentation\n",
      "medical\n",
      "ResNeSt: Split-Attention Networks\n",
      "Instance Segmentation\n",
      "computer vision\n",
      "End-to-End Object Detection with Transformers\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "SOLOv2: Dynamic and Fast Instance Segmentation\n",
      "Real-time Instance Segmentation\n",
      "computer vision\n",
      "Panoptic Feature Pyramid Networks\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "CenterMask : Real-Time Anchor-Free Instance Segmentation\n",
      "Real-time Instance Segmentation\n",
      "computer vision\n",
      "Hierarchical Multi-Scale Attention for Semantic Segmentation\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "PVTv2: Improved Baselines with Pyramid Vision Transformer\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation\n",
      "Panoptic Segmentation\n",
      "computer vision\n",
      "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space\n",
      "3D Point Cloud Classification\n",
      "computer vision\n",
      "SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "KPConv: Flexible and Deformable Convolution for Point Clouds\n",
      "LIDAR Semantic Segmentation\n",
      "computer vision\n",
      "3D Semantic Segmentation with Submanifold Sparse Convolutional Networks\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds\n",
      "LIDAR Semantic Segmentation\n",
      "computer vision\n",
      "SalsaNext: Fast, Uncertainty-aware Semantic Segmentation of LiDAR Point Clouds for Autonomous Driving\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "Shape-aware Semi-supervised 3D Semantic Segmentation for Medical Images\n",
      "3D Semantic Segmentation\n",
      "computer vision\n",
      "Constrained-CNN losses for weakly supervised segmentation\n",
      "Weakly supervised segmentation\n",
      "computer vision\n",
      "Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Puzzle-CAM: Improved localization via matching partial and full features\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Fully Convolutional Multi-Class Multiple Instance Learning\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Integral Object Mining via Online Attention Accumulation\n",
      "Weakly supervised segmentation\n",
      "computer vision\n",
      "HistoSegNet: Semantic Segmentation of Histological Tissue Type in Whole Slide Images\n",
      "whole slide images\n",
      "computer vision\n",
      "Self-supervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n",
      "Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation\n",
      "Weakly-Supervised Semantic Segmentation\n",
      "computer vision\n"
     ]
    }
   ],
   "source": [
    "cla1=[]\n",
    "cla2=[]\n",
    "\n",
    "for title in pdf_title['title'].values:\n",
    "    #for class2 \n",
    "    if title in second_classification.title.values:\n",
    "        find_cla2 = second_classification[second_classification['title'] == title]\n",
    "        for cla2s in find_cla2.values:\n",
    "            for cla2 in cla2s:\n",
    "                \n",
    "                cla2.append(cla2 for cla2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8af835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8fcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff7547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_classification.to_csv('second_classification-Copy1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e32fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_classification_dict=second_classification.set_index('title').to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc5984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_classification=first_classification_all.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51d1d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_classification에서 cla2가 중복되는 경우\n",
    "cla2_second_all = second_classification['cla2']\n",
    "cla2_first_list = first_classification\n",
    "#cla2_second=3255개\n",
    "tmp=[]\n",
    "cla1_from_cla2=[]\n",
    "\n",
    "\n",
    "for key, tmp_first in first_classification.items(): #16    \n",
    "  \n",
    "    for cla2_first in tmp_first: #782\n",
    "\n",
    "        for cla2_second in cla2_second_all: #여기도 cla2_second=3255\n",
    "            tmp.append(cla2_second)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if cla2_second == cla2_first:\n",
    "                if key == '':\n",
    "                    print(key)\n",
    "#                     raise\n",
    "                    \n",
    "#                 if cla2_first == '':\n",
    "                    \n",
    "#                     tmp.append(key)\n",
    "#                     print(key)\n",
    "            \n",
    "\n",
    "            #if cla2_second == cla2_first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1288e90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_classification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6024/1152035160.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msecond_classification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'second_classification-Copy1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'second_classification' is not defined"
     ]
    }
   ],
   "source": [
    "second_classification.to_csv('second_classification-Copy1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d00552",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_classification=pd.read_csv('second_classification.csv')\n",
    "words_titles=pd.read_csv('word-titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f069436",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_without_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3532/495112670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_without_word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcla2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msecond_classification\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcla1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassification_without_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{number}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{cla2}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_without_word' is not defined"
     ]
    }
   ],
   "source": [
    "second_classification=pd.read_csv('second_classification.csv')\n",
    "words_titles=pd.read_csv('word-titles.csv')\n",
    "\n",
    "#cla1_cla2_title=pd.merge(left=second_classification,right=classification_without_word, how='left',on=)\n",
    "\n",
    "\n",
    "for number in range(len(classification_without_word.columns)-1):\n",
    "    for cla2 in second_classification['0']:\n",
    "        cla1=classification_without_word[f'{number}'].str.contains(f'{cla2}')\n",
    "        cla_cla2_title[cla2]=cla1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "604f37ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18040/2774462418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtxt_file_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result = {}\n",
    "sorted_result = {}\n",
    "keywords=keywords_all['단어']\n",
    "replace_txt_name=[]\n",
    "\n",
    "\n",
    "for keyword in keywords:\n",
    "    result[keyword] = {}\n",
    "    \n",
    "    for txt_file in glob('./Downloads/pdf_download/txt/*.txt'):\n",
    "        txt_file_name = os.path.basename(txt_file).replace('.txt','')        \n",
    "        with open(txt_file, encoding='utf-8') as file:\n",
    "            sentences = file.read().lower().replace('-\\n', '').replace('\\n', ' ').split('.')\n",
    "        sentences = ' '.join(sentences)\n",
    "        count = sentences.count(keyword)        \n",
    "        \n",
    "        result[keyword][txt_file_name] = count              \n",
    "        for pdf_name in pdf_title_cla1_cla2.pdf.values:\n",
    "\n",
    "            if txt_file_name in pdf_name:\n",
    "                classification = pdf_title_cla1_cla2[pdf_title_cla1_cla2['pdf'].str.contains(txt_file_name)]\n",
    "                a = classification['cla1'].values\n",
    "                b = classification['cla2'].values\n",
    "\n",
    "                replace_txt_name.append(re.sub(r'[\\.0-9a-zA-Z]+', f'{a} - {b}', txt_file_name))\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        sorting = sorted(result[keyword], key= lambda x : result[keyword][x], reverse=True)[:5]\n",
    "        sorted_result[keyword] = sorting\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "332f00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_classification(txt_file_name):\n",
    "\n",
    "    for pdf_name in pdf_title_cla1_cla2.pdf.values:\n",
    "\n",
    "        if txt_file_name in pdf_name:\n",
    "            classification = pdf_title_cla1_cla2[pdf_title_cla1_cla2['pdf'].str.contains(txt_file_name)]\n",
    "            a = classification['cla1'].values\n",
    "            b = classification['cla2'].values\n",
    "            c = f'{a} - {b}'\n",
    "\n",
    "            return c\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9781f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_values=[]\n",
    "before_last={}\n",
    "count = 0\n",
    "last = {}\n",
    "the_result=[]\n",
    "\n",
    "for key, values in sorted_result.items():\n",
    "    for value in values:\n",
    "        the_result.append(find_classification(value))\n",
    "        count += 1\n",
    "\n",
    "    last[key] = the_result\n",
    "    if count == 5:\n",
    "        the_result =[]\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5cde8323",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'procedur': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Meta-Learning']\",\n",
       "  \"['methodology'] - ['Knowledge Distillation']\",\n",
       "  \"['computer vision'] - ['OOD Detection']\",\n",
       "  \"['natural language processing'] - ['Learning with noisy labels']\"],\n",
       " 'architectur': [\"['computer vision'] - ['Thermal Image Segmentation']\",\n",
       "  \"['medical'] - ['Brain Tumor Segmentation']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Knowledge Distillation']\"],\n",
       " 'imagenet': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Meta-Learning']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Document Layout Analysis']\"],\n",
       " 'augment': [\"['computer vision'] - ['Image Augmentation']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['OOD Detection']\",\n",
       "  \"['computer vision'] - ['Document Layout Analysis']\",\n",
       "  \"['methodology'] - ['Knowledge Distillation']\"],\n",
       " 'model': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['methodology'] - ['Knowledge Distillation']\",\n",
       "  \"['computer vision'] - ['Out-of-Distribution Detection']\",\n",
       "  \"['methodology'] - ['One-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Out-of-Distribution Detection']\"],\n",
       " 'differ': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['methodology'] - ['Knowledge Distillation']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Meta-Learning']\",\n",
       "  \"['computer vision'] - ['Instance Segmentation']\"],\n",
       " 'tabl': [\"['computer vision'] - ['Retinal OCT Disease Classification']\",\n",
       "  \"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Multi-Human Parsing']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Image Classification']\"],\n",
       " 'timm': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Document Layout Analysis']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Image Classification']\",\n",
       "  \"['computer vision'] - ['Weakly-Supervised Semantic Segmentation']\"],\n",
       " 'epoch': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['natural language processing'] - ['Learning with noisy labels']\",\n",
       "  \"['computer vision'] - ['Document Layout Analysis']\",\n",
       "  \"['computer vision'] - ['Instance Segmentation']\",\n",
       "  \"['medical'] - ['Brain Tumor Segmentation']\"],\n",
       " 'paramet': [\"['methodology'] - ['One-Shot Learning']\",\n",
       "  \"['computer vision'] - ['OOD Detection']\",\n",
       "  \"['computer vision'] - ['Panoptic Segmentation']\",\n",
       "  \"['computer vision'] - ['Crowd Counting']\",\n",
       "  \"['methodology'] - ['Few-Shot Learning']\"],\n",
       " 'top': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Panoptic Segmentation']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['computer vision'] - ['Image Classification']\",\n",
       "  \"['computer vision'] - ['Visual Question Answering']\"],\n",
       " 'seed': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Few-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Weakly-Supervised Semantic Segmentation']\",\n",
       "  \"['computer vision'] - ['Tumor Segmentation']\",\n",
       "  \"['computer vision'] - ['Visual Question Answering']\"],\n",
       " 'accuraci': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Few-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Thermal Image Segmentation']\",\n",
       "  \"['methodology'] - ['Zero-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\"],\n",
       " 'result': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Tumor Segmentation']\",\n",
       "  \"['medical'] - ['Brain Tumor Segmentation']\",\n",
       "  \"['computer vision'] - ['Multi-Human Parsing']\",\n",
       "  \"['computer vision'] - ['Object Localization']\"],\n",
       " 'batch': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['methodology'] - ['Few-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Thermal Image Segmentation']\",\n",
       "  \"['methodology'] - ['Few-Shot Learning']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\"],\n",
       " 'mixup': [\"['computer vision'] - ['Fine-Grained Image Classification']\",\n",
       "  \"['natural language processing'] - ['Learning with noisy labels']\",\n",
       "  \"['computer vision'] - ['Instance Segmentation']\",\n",
       "  \"['computer vision'] - ['Document Layout Analysis']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\"],\n",
       " 'comput': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Real-Time Object Detection']\",\n",
       "  \"['computer vision'] - ['Out-of-Distribution Detection']\",\n",
       "  \"['computer vision'] - ['Tumor Segmentation']\",\n",
       "  \"['computer vision'] - ['Retinal OCT Disease Classification']\"],\n",
       " 'vision': [\"['methodology'] - ['Few-Shot Image Classification']\",\n",
       "  \"['computer vision'] - ['Weakly-Supervised Semantic Segmentation']\",\n",
       "  \"['computer vision'] - ['Weakly supervised segmentation']\",\n",
       "  \"['computer vision'] - ['Weakly-Supervised Semantic Segmentation']\",\n",
       "  \"['computer vision'] - ['Fine-Grained Image Classification']\"]}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "eb8eeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_last=pd.DataFrame.from_dict(dict(last), orient='index')\n",
    "classification_last\n",
    "classification_last.to_csv('classification_last.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "58b50682",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_last = pd.read_csv('classification_last.csv', index_col=0)\n",
    "# classification_last.rename(columns={' ':'단어'}, inplace=True )\n",
    "classification_last.index.names =['단어']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "588fbbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>단어</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>procedur</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architectur</th>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagenet</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>augment</th>\n",
       "      <td>['computer vision'] - ['Image Augmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "      <td>['methodology'] - ['One-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differ</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabl</th>\n",
       "      <td>['computer vision'] - ['Retinal OCT Disease Cl...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Multi-Human Parsing']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timm</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paramet</th>\n",
       "      <td>['methodology'] - ['One-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['computer vision'] - ['Panoptic Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Crowd Counting']</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Panoptic Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "      <td>['computer vision'] - ['Visual Question Answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Visual Question Answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuraci</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['methodology'] - ['Zero-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Multi-Human Parsing']</td>\n",
       "      <td>['computer vision'] - ['Object Localization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixup</th>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comput</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Real-Time Object Detec...</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Retinal OCT Disease Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision</th>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Weakly supervised segm...</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0  \\\n",
       "단어                                                               \n",
       "procedur     ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "architectur  ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "imagenet     ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "augment           ['computer vision'] - ['Image Augmentation']   \n",
       "model        ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "differ       ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "tabl         ['computer vision'] - ['Retinal OCT Disease Cl...   \n",
       "timm         ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "epoch        ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "paramet                ['methodology'] - ['One-Shot Learning']   \n",
       "top          ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "seed         ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "accuraci     ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "result       ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "batch        ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "mixup        ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "comput       ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "vision       ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "\n",
       "                                                             1  \\\n",
       "단어                                                               \n",
       "procedur                   ['methodology'] - ['Meta-Learning']   \n",
       "architectur         ['medical'] - ['Brain Tumor Segmentation']   \n",
       "imagenet     ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "augment      ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "model             ['methodology'] - ['Knowledge Distillation']   \n",
       "differ            ['methodology'] - ['Knowledge Distillation']   \n",
       "tabl         ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "timm         ['computer vision'] - ['Document Layout Analys...   \n",
       "epoch        ['natural language processing'] - ['Learning w...   \n",
       "paramet                ['computer vision'] - ['OOD Detection']   \n",
       "top            ['computer vision'] - ['Panoptic Segmentation']   \n",
       "seed                   ['methodology'] - ['Few-Shot Learning']   \n",
       "accuraci               ['methodology'] - ['Few-Shot Learning']   \n",
       "result            ['computer vision'] - ['Tumor Segmentation']   \n",
       "batch                  ['methodology'] - ['Few-Shot Learning']   \n",
       "mixup        ['natural language processing'] - ['Learning w...   \n",
       "comput       ['computer vision'] - ['Real-Time Object Detec...   \n",
       "vision       ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "\n",
       "                                                             2  \\\n",
       "단어                                                               \n",
       "procedur          ['methodology'] - ['Knowledge Distillation']   \n",
       "architectur  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "imagenet                   ['methodology'] - ['Meta-Learning']   \n",
       "augment                ['computer vision'] - ['OOD Detection']   \n",
       "model        ['computer vision'] - ['Out-of-Distribution De...   \n",
       "differ       ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "tabl             ['computer vision'] - ['Multi-Human Parsing']   \n",
       "timm         ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "epoch        ['computer vision'] - ['Document Layout Analys...   \n",
       "paramet        ['computer vision'] - ['Panoptic Segmentation']   \n",
       "top          ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "seed         ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "accuraci     ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "result              ['medical'] - ['Brain Tumor Segmentation']   \n",
       "batch        ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "mixup          ['computer vision'] - ['Instance Segmentation']   \n",
       "comput       ['computer vision'] - ['Out-of-Distribution De...   \n",
       "vision       ['computer vision'] - ['Weakly supervised segm...   \n",
       "\n",
       "                                                             3  \\\n",
       "단어                                                               \n",
       "procedur               ['computer vision'] - ['OOD Detection']   \n",
       "architectur  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "imagenet     ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "augment      ['computer vision'] - ['Document Layout Analys...   \n",
       "model                  ['methodology'] - ['One-Shot Learning']   \n",
       "differ                     ['methodology'] - ['Meta-Learning']   \n",
       "tabl         ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "timm            ['computer vision'] - ['Image Classification']   \n",
       "epoch          ['computer vision'] - ['Instance Segmentation']   \n",
       "paramet               ['computer vision'] - ['Crowd Counting']   \n",
       "top             ['computer vision'] - ['Image Classification']   \n",
       "seed              ['computer vision'] - ['Tumor Segmentation']   \n",
       "accuraci              ['methodology'] - ['Zero-Shot Learning']   \n",
       "result           ['computer vision'] - ['Multi-Human Parsing']   \n",
       "batch                  ['methodology'] - ['Few-Shot Learning']   \n",
       "mixup        ['computer vision'] - ['Document Layout Analys...   \n",
       "comput            ['computer vision'] - ['Tumor Segmentation']   \n",
       "vision       ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "\n",
       "                                                             4  \n",
       "단어                                                              \n",
       "procedur     ['natural language processing'] - ['Learning w...  \n",
       "architectur       ['methodology'] - ['Knowledge Distillation']  \n",
       "imagenet     ['computer vision'] - ['Document Layout Analys...  \n",
       "augment           ['methodology'] - ['Knowledge Distillation']  \n",
       "model        ['computer vision'] - ['Out-of-Distribution De...  \n",
       "differ         ['computer vision'] - ['Instance Segmentation']  \n",
       "tabl            ['computer vision'] - ['Image Classification']  \n",
       "timm         ['computer vision'] - ['Weakly-Supervised Sema...  \n",
       "epoch               ['medical'] - ['Brain Tumor Segmentation']  \n",
       "paramet                ['methodology'] - ['Few-Shot Learning']  \n",
       "top          ['computer vision'] - ['Visual Question Answer...  \n",
       "seed         ['computer vision'] - ['Visual Question Answer...  \n",
       "accuraci     ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "result           ['computer vision'] - ['Object Localization']  \n",
       "batch        ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "mixup        ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "comput       ['computer vision'] - ['Retinal OCT Disease Cl...  \n",
       "vision       ['computer vision'] - ['Fine-Grained Image Cla...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "01ec6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_last = pd.merge(left = keywords_all, right = classification_last, how='left', on = '단어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7a3e1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>의미/해석</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>procedur</td>\n",
       "      <td>['In deep learning, a computer model learns to...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>architectur</td>\n",
       "      <td>['The basic deep learning architecture has a f...</td>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagenet</td>\n",
       "      <td>['ImageNet is an image database organized acco...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>augment</td>\n",
       "      <td>['Data augmentation is a set of techniques to ...</td>\n",
       "      <td>['computer vision'] - ['Image Augmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model</td>\n",
       "      <td>['In deep learning, a computer model learns to...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "      <td>['methodology'] - ['One-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>differ</td>\n",
       "      <td>[\"Machine learning means computers learning fr...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['methodology'] - ['Knowledge Distillation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Meta-Learning']</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tabl</td>\n",
       "      <td>['Building a deep learning model with TensorFl...</td>\n",
       "      <td>['computer vision'] - ['Retinal OCT Disease Cl...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Multi-Human Parsing']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>timm</td>\n",
       "      <td>['`timm` is a deep-learning library created by...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>epoch</td>\n",
       "      <td>['An epoch is a term used in machine learning ...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paramet</td>\n",
       "      <td>['Model Parameters are properties of training ...</td>\n",
       "      <td>['methodology'] - ['One-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['OOD Detection']</td>\n",
       "      <td>['computer vision'] - ['Panoptic Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Crowd Counting']</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>top</td>\n",
       "      <td>['Here is the list of top 10 most popular deep...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Panoptic Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['computer vision'] - ['Image Classification']</td>\n",
       "      <td>['computer vision'] - ['Visual Question Answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>seed</td>\n",
       "      <td>['The “seed” is a starting point for the seque...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Visual Question Answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accuraci</td>\n",
       "      <td>['Accuracy is a metric that generally describe...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['methodology'] - ['Zero-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result</td>\n",
       "      <td>[\"It's achieving results that were not possibl...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['medical'] - ['Brain Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Multi-Human Parsing']</td>\n",
       "      <td>['computer vision'] - ['Object Localization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>batch</td>\n",
       "      <td>['The batch size is a number of samples proces...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Thermal Image Segmenta...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Learning']</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mixup</td>\n",
       "      <td>['Mixup [40] is a recently proposed method for...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "      <td>['natural language processing'] - ['Learning w...</td>\n",
       "      <td>['computer vision'] - ['Instance Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Document Layout Analys...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>comput</td>\n",
       "      <td>['Deep learning is a machine learning techniqu...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Real-Time Object Detec...</td>\n",
       "      <td>['computer vision'] - ['Out-of-Distribution De...</td>\n",
       "      <td>['computer vision'] - ['Tumor Segmentation']</td>\n",
       "      <td>['computer vision'] - ['Retinal OCT Disease Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vision</td>\n",
       "      <td>['Computer vision algorithms analyze certain c...</td>\n",
       "      <td>['methodology'] - ['Few-Shot Image Classificat...</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Weakly supervised segm...</td>\n",
       "      <td>['computer vision'] - ['Weakly-Supervised Sema...</td>\n",
       "      <td>['computer vision'] - ['Fine-Grained Image Cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             단어                                              의미/해석  \\\n",
       "0      procedur  ['In deep learning, a computer model learns to...   \n",
       "1   architectur  ['The basic deep learning architecture has a f...   \n",
       "2      imagenet  ['ImageNet is an image database organized acco...   \n",
       "3       augment  ['Data augmentation is a set of techniques to ...   \n",
       "4         model  ['In deep learning, a computer model learns to...   \n",
       "5        differ  [\"Machine learning means computers learning fr...   \n",
       "6          tabl  ['Building a deep learning model with TensorFl...   \n",
       "7          timm  ['`timm` is a deep-learning library created by...   \n",
       "8         epoch  ['An epoch is a term used in machine learning ...   \n",
       "9       paramet  ['Model Parameters are properties of training ...   \n",
       "10          top  ['Here is the list of top 10 most popular deep...   \n",
       "11         seed  ['The “seed” is a starting point for the seque...   \n",
       "12     accuraci  ['Accuracy is a metric that generally describe...   \n",
       "13       result  [\"It's achieving results that were not possibl...   \n",
       "14        batch  ['The batch size is a number of samples proces...   \n",
       "15        mixup  ['Mixup [40] is a recently proposed method for...   \n",
       "16       comput  ['Deep learning is a machine learning techniqu...   \n",
       "17       vision  ['Computer vision algorithms analyze certain c...   \n",
       "\n",
       "                                                    0  \\\n",
       "0   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "1   ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "2   ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "3        ['computer vision'] - ['Image Augmentation']   \n",
       "4   ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "5   ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "6   ['computer vision'] - ['Retinal OCT Disease Cl...   \n",
       "7   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "8   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "9             ['methodology'] - ['One-Shot Learning']   \n",
       "10  ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "11  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "12  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "13  ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "14  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "15  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "16  ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "17  ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "\n",
       "                                                    1  \\\n",
       "0                 ['methodology'] - ['Meta-Learning']   \n",
       "1          ['medical'] - ['Brain Tumor Segmentation']   \n",
       "2   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "3   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "4        ['methodology'] - ['Knowledge Distillation']   \n",
       "5        ['methodology'] - ['Knowledge Distillation']   \n",
       "6   ['methodology'] - ['Few-Shot Image Classificat...   \n",
       "7   ['computer vision'] - ['Document Layout Analys...   \n",
       "8   ['natural language processing'] - ['Learning w...   \n",
       "9             ['computer vision'] - ['OOD Detection']   \n",
       "10    ['computer vision'] - ['Panoptic Segmentation']   \n",
       "11            ['methodology'] - ['Few-Shot Learning']   \n",
       "12            ['methodology'] - ['Few-Shot Learning']   \n",
       "13       ['computer vision'] - ['Tumor Segmentation']   \n",
       "14            ['methodology'] - ['Few-Shot Learning']   \n",
       "15  ['natural language processing'] - ['Learning w...   \n",
       "16  ['computer vision'] - ['Real-Time Object Detec...   \n",
       "17  ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "\n",
       "                                                    2  \\\n",
       "0        ['methodology'] - ['Knowledge Distillation']   \n",
       "1   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "2                 ['methodology'] - ['Meta-Learning']   \n",
       "3             ['computer vision'] - ['OOD Detection']   \n",
       "4   ['computer vision'] - ['Out-of-Distribution De...   \n",
       "5   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "6       ['computer vision'] - ['Multi-Human Parsing']   \n",
       "7   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "8   ['computer vision'] - ['Document Layout Analys...   \n",
       "9     ['computer vision'] - ['Panoptic Segmentation']   \n",
       "10  ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "11  ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "12  ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "13         ['medical'] - ['Brain Tumor Segmentation']   \n",
       "14  ['computer vision'] - ['Thermal Image Segmenta...   \n",
       "15    ['computer vision'] - ['Instance Segmentation']   \n",
       "16  ['computer vision'] - ['Out-of-Distribution De...   \n",
       "17  ['computer vision'] - ['Weakly supervised segm...   \n",
       "\n",
       "                                                    3  \\\n",
       "0             ['computer vision'] - ['OOD Detection']   \n",
       "1   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "2   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "3   ['computer vision'] - ['Document Layout Analys...   \n",
       "4             ['methodology'] - ['One-Shot Learning']   \n",
       "5                 ['methodology'] - ['Meta-Learning']   \n",
       "6   ['computer vision'] - ['Fine-Grained Image Cla...   \n",
       "7      ['computer vision'] - ['Image Classification']   \n",
       "8     ['computer vision'] - ['Instance Segmentation']   \n",
       "9            ['computer vision'] - ['Crowd Counting']   \n",
       "10     ['computer vision'] - ['Image Classification']   \n",
       "11       ['computer vision'] - ['Tumor Segmentation']   \n",
       "12           ['methodology'] - ['Zero-Shot Learning']   \n",
       "13      ['computer vision'] - ['Multi-Human Parsing']   \n",
       "14            ['methodology'] - ['Few-Shot Learning']   \n",
       "15  ['computer vision'] - ['Document Layout Analys...   \n",
       "16       ['computer vision'] - ['Tumor Segmentation']   \n",
       "17  ['computer vision'] - ['Weakly-Supervised Sema...   \n",
       "\n",
       "                                                    4  \n",
       "0   ['natural language processing'] - ['Learning w...  \n",
       "1        ['methodology'] - ['Knowledge Distillation']  \n",
       "2   ['computer vision'] - ['Document Layout Analys...  \n",
       "3        ['methodology'] - ['Knowledge Distillation']  \n",
       "4   ['computer vision'] - ['Out-of-Distribution De...  \n",
       "5     ['computer vision'] - ['Instance Segmentation']  \n",
       "6      ['computer vision'] - ['Image Classification']  \n",
       "7   ['computer vision'] - ['Weakly-Supervised Sema...  \n",
       "8          ['medical'] - ['Brain Tumor Segmentation']  \n",
       "9             ['methodology'] - ['Few-Shot Learning']  \n",
       "10  ['computer vision'] - ['Visual Question Answer...  \n",
       "11  ['computer vision'] - ['Visual Question Answer...  \n",
       "12  ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "13      ['computer vision'] - ['Object Localization']  \n",
       "14  ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "15  ['computer vision'] - ['Fine-Grained Image Cla...  \n",
       "16  ['computer vision'] - ['Retinal OCT Disease Cl...  \n",
       "17  ['computer vision'] - ['Fine-Grained Image Cla...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "005da687",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_result = last_last.to_html('결과.html', encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
